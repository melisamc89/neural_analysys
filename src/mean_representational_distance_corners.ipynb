{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada84b1e-fcf2-4e73-9bf9-c688b74acef1",
   "metadata": {},
   "source": [
    "### Measuring distance between positions using multiple transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2c3fe9-cd9d-4753-ab46-d134b3406a55",
   "metadata": {},
   "source": [
    "Here we measure the distance between corners representations using different transformation on the neural data. Complete data, PC, CC and LDA transformations. \n",
    "\n",
    "We run a shufflinf analysis over the balanced data. The shuffling is done over different events, where we define as an event the complete visit to the corner. \n",
    "\n",
    "Visits are only taken if they are longer than 2s, and the balancing is done from shorter to longer events, meaning that, if necessary, we leave aside long visits to the corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d88335-59c1-40c4-b6bf-c5fdb2c6c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import configuration\n",
    "import general_statistics as stats\n",
    "import figures as figs\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from scipy import signal\n",
    "from scipy import stats as sstats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "cmap = cm.jet\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2500176-93ee-493c-b7a9-bb355b84569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_selection(tracking = None, speed_limit = 3):\n",
    "    \n",
    "    x = tracking[0,:]\n",
    "    y = tracking[1,:]\n",
    "    vx = np.diff(x)\n",
    "    vy = np.diff(y)\n",
    "    speed = np.sqrt(vx*vx+vy*vy)\n",
    "    index = np.where(speed > speed_limit)[0]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf459e86-d454-4a28-9f3a-97c208f206e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mouse information, and preprocessin versions from analysis.\n",
    "# load data for all sessions in this mouse and compute mean activity for each neuron.\n",
    "\n",
    "mouse = 56165      ### mouse number id\n",
    "decoding_v = 1            ## decoding version, normaly equal to one\n",
    "motion_correction_v = 20  ### 100 means everything was aligned, 200 means it was also equalized, 20 is for day wise\n",
    "alignment_v = 3           ## alignment version, version 3 is for day wise\n",
    "equalization_v = 0        ## equalization version\n",
    "source_extraction_v = 1   ## source extraction version\n",
    "component_evaluation_v = 1 ## component evaluation version\n",
    "\n",
    "# here we will do analysis with no registration\n",
    "# registration_v = 2        ## registration version\n",
    "sf = 10                   ## sampling frequency of the original signal \n",
    "re_sf= 1                 ## value of resampling\n",
    "session_now = 1\n",
    "period = int(10 * sf / re_sf)\n",
    "period_resting = period *50\n",
    "fixed = 'None'\n",
    "N_SHUFFLINGS = 50\n",
    "## define task for plotting. This will cahnge for other mice!!!!\n",
    "colorcodes = ['Greys','PuBu', 'YlOrRd','Reds','Blues','Oranges','Greens']\n",
    "if mouse == 411857:\n",
    "    sessions = [1,2,3]\n",
    "    if session_now == 1:\n",
    "        task = 'STABLE'\n",
    "        colapse_behaviour = 2\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "    if session_now == 2:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "    if session_now == 3:\n",
    "        task = 'OVERLAPPING'\n",
    "        fixed = 'LL'\n",
    "        object_fixed = 3\n",
    "        colapse_behaviour = 1\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "\n",
    "\n",
    "if mouse == 56165 or mouse == 32364:\n",
    "    if mouse == 56165:\n",
    "        sessions = [1,2,4]       ## sessions for this particular mouse\n",
    "    if mouse == 32364:\n",
    "        sessions = [1,2]\n",
    "    if session_now == 1:\n",
    "        task = 'OVERLAPPING'\n",
    "        colapse_behaviour = 1\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "        if mouse == 32364:\n",
    "            fixed = 'LR'\n",
    "            object_fixed = 4\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "        if mouse == 56165:\n",
    "            fixed = 'UR'\n",
    "            object_fixed = 5\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'STABLE'\n",
    "            colapse_behaviour = 2\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "        else:\n",
    "            task = 'RANDOM'\n",
    "            colapse_behaviour = 0\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32365:\n",
    "    sessions = [2,3] ## sessions for this particular mouse\n",
    "    if session_now == 2:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "    else:\n",
    "        if session_now == 3:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'LR'\n",
    "            object_fixed = 4\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]           \n",
    "            \n",
    "if mouse == 56166:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UR'\n",
    "            object_fixed = 5\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32366:\n",
    "    sessions = [2,3] ## sessions for this particular mouse\n",
    "    if session_now == 3:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32363:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UL'\n",
    "            object_fixed = 6\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ab975ac-73da-4fba-afc4-6695cc69f7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = os.environ['PROJECT_DIR'] + 'neural_analysis/data/calcium_activity_day_wise/'\n",
    "timeline_file_dir = os.environ['PROJECT_DIR'] + 'neural_analysis/data/timeline/'\n",
    "behaviour_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/ethogram/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "behaviour_dir_parameters = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/ethogram_parameters/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "tracking_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/center_of_mass/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "objects_dir= os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/object_positions/'\n",
    "figure_path = os.environ['PROJECT_DIR'] +'neural_analysis/figures/trial_aligned_events/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31be2fc0-8172-4eb4-adc6-d9f5fe302ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING TRIALS ACTIVITY AND CREATING LIST OF ACTIVITY, TRACKING AND BEHAVIOUR\n",
      "(195, 32368)\n",
      "(448, 30592)\n",
      "(322, 31977)\n",
      "(397, 30905)\n"
     ]
    }
   ],
   "source": [
    "# define all relevant files names and load them into a list\n",
    "session = session_now\n",
    "\n",
    "activity_list = []\n",
    "timeline_list = []\n",
    "behaviour_list = []\n",
    "corners_list = []\n",
    "corners_list2 = []\n",
    "\n",
    "speed_list = []\n",
    "\n",
    "behaviour_list_unsup = []\n",
    "parameters_list = []\n",
    "parameters_list2 = []\n",
    "parameters_time = []\n",
    "tracking_list = []\n",
    "total_time = 0\n",
    "day = 0\n",
    "\n",
    "print('LOADING TRIALS ACTIVITY AND CREATING LIST OF ACTIVITY, TRACKING AND BEHAVIOUR')\n",
    "for trial in [1,6,11,16]:\n",
    "\n",
    "    beh_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_day_' + f'{day+1}' + '_likelihood_0.75_ethogram.npy'\n",
    "    ## LOAD BEHAVIOUR\n",
    "    behaviour = np.load(behaviour_dir + beh_file_name_1)\n",
    "    reshape_behaviour = np.reshape(behaviour[:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "    resample_beh1 = np.reshape(scipy.stats.mode(reshape_behaviour,axis=1)[0],reshape_behaviour.shape[0])\n",
    "\n",
    "    beh_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_day_' + f'{day+1}' + '_likelihood_0.75_object_corners.npy'\n",
    "    ## LOAD CORNERS EXPLORATION\n",
    "    behaviour = np.load(behaviour_dir + beh_file_name_1)\n",
    "    reshape_behaviour = np.reshape(behaviour[:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "    corners = np.reshape(scipy.stats.mode(reshape_behaviour,axis=1)[0],reshape_behaviour.shape[0])\n",
    "\n",
    "    speed_file_name = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_day_' + f'{day+1}' + '_likelihood_0.75_speed.npy'\n",
    "    ## LOAD INSTANTANEOUS SPEED\n",
    "    speed = np.load(behaviour_dir + speed_file_name)\n",
    "    reshape_speed = np.reshape(speed[:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "    resample_speed = np.reshape(scipy.stats.mode(reshape_speed,axis=1)[0],reshape_speed.shape[0])\n",
    "    \n",
    "    \n",
    "    beh_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_trial_' + f'{day+1}' + '_likelihood_0.75_ethogram_parameters.npy'\n",
    "    ## LOAD PARAMETRS FOR BEHAVIOUR CLASSIFICATION\n",
    "    parameters = np.load(behaviour_dir_parameters + beh_file_name_1)\n",
    "    \n",
    "    params0 = []\n",
    "    params = []\n",
    "    for param in range(0,2): ## take only ALLOCENTRIC REPRESENTATION\n",
    "        r1_params = np.reshape(parameters[param,:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "        r2_params = np.reshape(scipy.stats.mode(r1_params,axis=1)[0],reshape_behaviour.shape[0])\n",
    "        r_params = parameters[param,:resample_speed.shape[0]]\n",
    "        r_params[:r2_params.shape[0]] = r2_params\n",
    "        params.append(r_params)\n",
    "    resample_params0 = np.array(params)\n",
    "    \n",
    "    params = []\n",
    "    for param in range(2,7): ## take only ALLOCENTRIC REPRESENTATION\n",
    "        r1_params = np.reshape(parameters[param,:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "        r2_params = np.reshape(scipy.stats.mode(r1_params,axis=1)[0],reshape_behaviour.shape[0])\n",
    "        r_params = parameters[param,:resample_speed.shape[0]]\n",
    "        r_params[:r2_params.shape[0]] = r2_params\n",
    "        params.append(r_params)\n",
    "    resample_params = np.array(params)\n",
    "    \n",
    "    params2 = []\n",
    "    for param in range(7,11): ## take only ALLOCENTRIC REPRESENTATION\n",
    "        r1_params = np.reshape(parameters[param,:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "        r2_params = np.reshape(scipy.stats.mode(r1_params,axis=1)[0],reshape_behaviour.shape[0])\n",
    "        r_params = parameters[param,:resample_speed.shape[0]]\n",
    "        r_params[:r2_params.shape[0]] = r2_params\n",
    "        params.append(r_params)\n",
    "    resample_params2 = np.array(params)\n",
    "    \n",
    "    ## LOAD TRACKING\n",
    "    tracking_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_day_' + f'{day+1}' + '_likelihood_0.75.npy'\n",
    "    position = np.load(tracking_dir + tracking_file_name_1)\n",
    "    resample_position, resample_position_stc = stats.resample_matrix(neural_activity=position.T,\n",
    "                                                                                            re_sf=re_sf)\n",
    "    ## LOAD TIMELINE\n",
    "    time_file_session_1 =  'mouse_'+ f'{mouse}'+'_session_'+ f'{session}' +'_trial_'+ f'{trial}'+'_v1.3.1.0_10.pkl'\n",
    "\n",
    "    timeline_file= open(timeline_file_dir + time_file_session_1,'rb')\n",
    "    timeline_info = pickle.load(timeline_file)\n",
    "    timeline_1 = np.zeros(len(timeline_info) + 1)\n",
    "    for i in range(len(timeline_info)):\n",
    "        timeline_1[i] = timeline_info[i][1]\n",
    "    timeline_1[len(timeline_info)] = behaviour.shape[0]\n",
    "    timeline = timeline_1/re_sf\n",
    "    time_lenght = 10\n",
    "    resample_timeline = timeline_1/re_sf\n",
    "    timeline_list.append(resample_timeline)\n",
    "\n",
    "    behaviour_list.append(resample_beh1)\n",
    "    corners_list.append(corners)\n",
    "    speed_list.append(resample_speed)\n",
    "\n",
    "    parameters_list.append(resample_params)\n",
    "    parameters_list2.append(resample_params2)\n",
    "    parameters_time.append(resample_params0)\n",
    "    tracking_list.append(resample_position)\n",
    "    total_time = total_time + behaviour.shape[0]\n",
    "\n",
    "\n",
    "    file_name_session_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_trial_'+ f'{trial}'+'_v' + f'{decoding_v}' + '.4.' + f'{motion_correction_v}' + \\\n",
    "                            '.' + f'{alignment_v}' + '.' + f'{equalization_v}' + '.' + f'{source_extraction_v}' + '.' + \\\n",
    "                          f'{component_evaluation_v}' +  '.0.npy'\n",
    "\n",
    "     ##load activity and timeline\n",
    "    activity = np.load(file_directory + file_name_session_1)\n",
    "    neural_activity1 = activity[1:,:]\n",
    "    ## z-score neural activity\n",
    "    neural_activity = neural_activity1[:,:int(int(behaviour.shape[0]/re_sf)*re_sf)]\n",
    "    ##downsample neural activity\n",
    "    resample_neural_activity_mean, resample_neural_activity_std = stats.resample_matrix(neural_activity=neural_activity,\n",
    "                                                                                            re_sf=re_sf)\n",
    "\n",
    "    activity_list.append(resample_neural_activity_mean)\n",
    "    print(resample_neural_activity_mean.shape)\n",
    "\n",
    "    day = day + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4c6f61c-cf36-4e0f-b76e-1f108aa8c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 0\n",
    "pca = PCA()\n",
    "activity_list_pca = []\n",
    "variance_list = []\n",
    "variance_ratio_list = []\n",
    "\n",
    "activity_list2 = []\n",
    "\n",
    "cca_components = min(5,activity_list[day].shape[0])\n",
    "cca = CCA(n_components=cca_components)\n",
    "cca_components2 = 4\n",
    "cca2 = CCA(n_components=cca_components2)\n",
    "cca_components0 = 2\n",
    "cca0 = CCA(n_components=cca_components0)\n",
    "\n",
    "activity_list_cca = []\n",
    "activity_list_cca2 = []\n",
    "activity_list_cca0 = []\n",
    "\n",
    "clf = LDA()\n",
    "activity_list_lda = []\n",
    "\n",
    "#embedding = MDS(n_components=3)\n",
    "\n",
    "for day in range(len(behaviour_list))\n",
    "    \n",
    "    ### run pca on the entire dataset\n",
    "    pca.fit(activity_list[day].T)\n",
    "    transformed_activity = pca.fit(activity_list[day].T).transform(activity_list[day].T)\n",
    "    #X_pc_transformed = embedding.fit_transform(transformed_activity.T)\n",
    "    activity_list_pca.append(transformed_activity.T)\n",
    "    variance_list.append(pca.explained_variance_/(1+np.sqrt(activity_list[day].shape[0]/activity_list[day].shape[1]))**2)\n",
    "    normalized_variance = pca.explained_variance_/(1+np.sqrt(activity_list[day].shape[0]/activity_list[day].shape[1]))**2\n",
    "    variance_ratio_list.append(np.cumsum(normalized_variance/sum(normalized_variance)))\n",
    "    \n",
    "    X = activity_list[day].T\n",
    "    y = behaviour_list[day]\n",
    "    X_transformed = clf.fit(X, y).transform(X)\n",
    "    #X_lda_transformed = embedding.fit_transform(X_transformed.T)\n",
    "    activity_list_lda.append(X_transformed.T)\n",
    "\n",
    "    cca_transformed = cca0.fit(activity_list[day].T, parameters_list[day].T).transform(activity_list[day].T)\n",
    "    #X_cc_transformed = embedding.fit_transform(cca_transformed.T)    \n",
    "    activity_list_cca0.append(cca_transformed)\n",
    "    \n",
    "    cca_transformed = cca.fit(activity_list[day].T, parameters_list[day].T).transform(activity_list[day].T)\n",
    "    #X_cc_transformed = embedding.fit_transform(cca_transformed.T)    \n",
    "    activity_list_cca.append(cca_transformed)\n",
    "    \n",
    "        \n",
    "    cca_transformed = cca2.fit(activity_list[day].T, parameters_list2[day].T).transform(activity_list[day].T)\n",
    "    #X_cc_transformed = embedding.fit_transform(cca_transformed.T)    \n",
    "    activity_list_cca2.append(cca_transformed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5934e6af-5138-4175-91be-e829d55873e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffa7342a-7b67-4040-b913-27ae13e374f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REDIFINING BEHAVIOUR FOR DIFFERENT SESSIONS\n"
     ]
    }
   ],
   "source": [
    "    ## define targets of behaviour according to protocol (random, overlapping and stable)\n",
    "\n",
    "    id_target = [0,1,2,3,4] # 0: unlabeled, 1:resting, 2:Navigation, 3: Obj1, 4:Obj2, 5:Run1, 6:Run2\n",
    "    \n",
    "    print('REDIFINING BEHAVIOUR FOR DIFFERENT SESSIONS')\n",
    "\n",
    "    if colapse_behaviour == 0 : # RANDOM\n",
    "        for day in range(len(behaviour_list)):\n",
    "            for trial in range(5):\n",
    "                behaviour_trial = behaviour_list[day][int(timeline_list[day][2*trial]):int(timeline_list[day][2*trial+1])]\n",
    "                objects = np.unique(behaviour_trial)\n",
    "                selected_object = np.random.randint(len(objects)-4,len(objects)-2,1)\n",
    "                index0 = np.where(behaviour_trial==objects[selected_object])[0]\n",
    "                index1 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-4], behaviour_trial!=objects[selected_object]))[0]\n",
    "                index2 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-3], behaviour_trial!=objects[selected_object]))[0]\n",
    "                behaviour_trial[index0] = 3\n",
    "                behaviour_trial[index1] = 4\n",
    "\n",
    "                behaviour_trial[index2] = 4            \n",
    "\n",
    "                index0 = np.where(behaviour_trial==objects[selected_object]+4)[0]\n",
    "                index1 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-2], behaviour_trial!=objects[selected_object]+4))[0]\n",
    "                index2 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-1], behaviour_trial!=objects[selected_object]+4))[0]\n",
    "                behaviour_trial[index0] = 0\n",
    "                behaviour_trial[index1] = 0\n",
    "                behaviour_trial[index2] = 0 \n",
    "\n",
    "                behaviour_list[day][int(timeline_list[day][2*trial]):int(timeline_list[day][2*trial+1])] = behaviour_trial\n",
    "\n",
    "\n",
    "    if colapse_behaviour == 1 : #OVERLAPPING\n",
    "        for day in range(len(behaviour_list)):\n",
    "            behaviour_list[day][np.where(behaviour_list[day] == object_fixed)[0]] = 100\n",
    "            behaviour_list[day][np.where(np.logical_and(behaviour_list[day]>=3, behaviour_list[day]<=6))[0]] = 4\n",
    "            behaviour_list[day][np.where(behaviour_list[day] == 100)[0]] = 3        \n",
    "            behaviour_list[day][np.where(behaviour_list[day] == object_fixed +4)[0]] = 0        \n",
    "            behaviour_list[day][np.where(np.logical_and(behaviour_list[day]>=7, behaviour_list[day]<=10))[0]] = 0\n",
    "            behaviour_list[day][np.where(behaviour_list[day] == 200)[0]] = 0\n",
    "\n",
    "\n",
    "    if colapse_behaviour == 2: #STABLE\n",
    "        for day in range(len(behaviour_list)):\n",
    "            objects = np.unique(behaviour_list[day])\n",
    "            selected_object = np.random.randint(len(objects)-4,len(objects)-2,1)\n",
    "            index0 = np.where(behaviour_list[day]==objects[selected_object])[0]\n",
    "            index1 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-4], behaviour_list[day]!=objects[selected_object]))\n",
    "            index2 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-3], behaviour_list[day]!=objects[selected_object]))\n",
    "            behaviour_list[day][index0] = 3\n",
    "            behaviour_list[day][index1] = 4\n",
    "            behaviour_list[day][index2] = 4      \n",
    "\n",
    "            index0 = np.where(behaviour_list[day]==objects[selected_object]+4)[0]\n",
    "            index1 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-2], behaviour_list[day]!=objects[selected_object]+4))\n",
    "            index2 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-1], behaviour_list[day]!=objects[selected_object]+4))\n",
    "            behaviour_list[day][index0] = 0\n",
    "            behaviour_list[day][index1] = 0\n",
    "            behaviour_list[day][index2] = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd5e4ecc-f776-4dd8-a7f2-1429a055e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING NAVIGATION OF CORNERS AND EXPLORATION OF CORNERS VECTORS\n"
     ]
    }
   ],
   "source": [
    "print('CREATING NAVIGATION OF CORNERS AND EXPLORATION OF CORNERS VECTORS')\n",
    "\n",
    "navigation_list = [] \n",
    "exploration_list = []\n",
    "\n",
    "SPEED_LIMIT = 5\n",
    "for day in range(len(behaviour_list)):\n",
    "    speed = signal.medfilt(speed_list[day],9)\n",
    "    # select the corners that are being explored when the animal is doing an exploratory task\n",
    "    explorating_object = np.zeros_like(corners_list[day])\n",
    "    explorating_object[np.where(behaviour_list[day]==4)[0]] = corners_list[day][np.where(behaviour_list[day]==4)[0]]\n",
    "    explorating_object[np.where(behaviour_list[day]==3)[0]] = corners_list[day][np.where(behaviour_list[day]==3)[0]]\n",
    "    #exploration_corner = np.zeros_like(explorating_object)\n",
    "    # create a vector that contains zeros everywhere but object ID number when the animal is exploring an object a particular corner with low speed\n",
    "    #exploration_corner[np.where(speed<SPEED_LIMIT)[0]] = navigation[np.where(speed<SPEED_LIMIT)[0]]\n",
    "    #exploration_corner = explorating_object\n",
    "    \n",
    "    navigation_corner = np.zeros_like(corners_list[day])\n",
    "    for corner in [1,2,3,4]:\n",
    "        # create a vector that contains zeros everywhere but corner ID when the animal is navigation at that position with out an object\n",
    "        navigations_at_corner = np.logical_and(explorating_object==0,corners_list[day]==corner)\n",
    "        #print(len(np.where(navigations_at_corner)[0]))\n",
    "        #navigation_corner[np.logical_and(navigations_at_corner, speed < SPEED_LIMIT)] = corner\n",
    "        navigation_corner[navigations_at_corner] = corner\n",
    "        \n",
    "    navigation_list.append(navigation_corner)\n",
    "    exploration_list.append(explorating_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99e4563e-8402-418c-b196-2006d3ab4347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATES LIST THAT SAVES ALL THE EVENTS IN A DAY AND CONTAINS ONSET OF VISITS\n"
     ]
    }
   ],
   "source": [
    "print('CREATES LIST THAT SAVES ALL THE EVENTS IN A DAY AND CONTAINS ONSET OF VISITS')\n",
    "\n",
    "# for each day creates a list that counts and saves times of different events.\n",
    "events_day_list_1 = []\n",
    "events_day_list_shuffle_1 = []\n",
    "\n",
    "events_counter_day_list = []\n",
    "events_time_starts_day = []\n",
    "\n",
    "for day in range(len(navigation_list)):\n",
    "    events_list = []\n",
    "    events_counter_list = []\n",
    "    events_time_starts = []\n",
    "    random_events = []\n",
    "    start_counter = 100\n",
    "    counter = 0\n",
    "    #for i in range(exploration_list[day].shape[0]):\n",
    "    for i in range(navigation_list[day].shape[0]):\n",
    "        #if exploration_list[day][i] != start_counter:\n",
    "        if navigation_list[day][i] != start_counter:\n",
    "            events_list.append(start_counter) # contains a sequence of events ID\n",
    "            events_counter_list.append(counter) # conteins the duration of each event\n",
    "            events_time_starts.append(i) # contains the time at which event starts\n",
    "            #start_counter = behaviour_list[day][i] \n",
    "            #start_counter = exploration_list[day][i]\n",
    "            start_counter = navigation_list[day][i]\n",
    "            counter = 1\n",
    "        else:\n",
    "            counter = counter + 1    \n",
    "            \n",
    "            \n",
    "    events_day_list_1.append(events_list)\n",
    "    shufflings = []\n",
    "    for j in range(N_SHUFFLINGS):\n",
    "        shufflings.append(events_list.copy())\n",
    "    events_day_list_shuffle_1.append(shufflings)\n",
    "    events_counter_day_list.append(events_counter_list)\n",
    "    events_time_starts_day.append(events_time_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ad371c5-c966-441f-a80e-cf377142148a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOW WE SEPARATE EVENTS TYPES ACCORDING TO CORNER/OBJECT VISIT\n"
     ]
    }
   ],
   "source": [
    "print('NOW WE SEPARATE EVENTS TYPES ACCORDING TO CORNER/OBJECT VISIT')\n",
    "## compute events duration for type of event. Here we create lists that we can access to know the duration of each ID event\n",
    "## we will use this to balance the dataset\n",
    "selection_target = [1,2,3,4]    # here we balcance the data only for this targets of behaviour\n",
    "id_target = selection_target\n",
    "\n",
    "events_duration_list = []\n",
    "total_duration_list = []\n",
    "number_of_events_list = []\n",
    "events_id = []\n",
    "\n",
    "for day in range(len(behaviour_list)):\n",
    "    events_duration_day = []\n",
    "    total_duration_day = []\n",
    "    number_of_events_day = []\n",
    "    events_id_day = []\n",
    "    \n",
    "    events = np.array(events_day_list_1[day])  # all events in a day (THIS IS EVENT ID)\n",
    "    events_counter = np.array(events_counter_day_list[day]) #duration of all day events\n",
    "    events_time = np.array(events_time_starts_day[day]) # start time of events in day\n",
    "\n",
    "    for target in id_target:\n",
    "        position_events = np.where(events == target)[0] # select events related to one specific ID\n",
    "        events_duration_target = events_counter[position_events]   # take the duration of the events for that ID\n",
    "        \n",
    "        if(len(events_duration_target)):\n",
    "            events_duration_day.append(events_duration_target)\n",
    "            total_duration_day.append(np.sum(events_duration_target))\n",
    "            number_of_events_day.append(len(events_duration_target ))\n",
    "            events_id_day.append(target)\n",
    "            \n",
    "    events_duration_list.append(events_duration_day)\n",
    "    total_duration_list.append(total_duration_day)\n",
    "    number_of_events_list.append(number_of_events_day)\n",
    "    events_id.append(events_id_day)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aea5a093-eff4-4850-8e89-a43e0f692b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BALANCING TO THE LOWER NUMBER OF VISITS\n",
      "Number of events per day after balancing:  11\n",
      "Number of events per day after balancing:  34\n",
      "Number of events per day after balancing:  25\n",
      "Number of events per day after balancing:  25\n"
     ]
    }
   ],
   "source": [
    "print('BALANCING TO THE LOWER NUMBER OF VISITS')\n",
    "### Balancing the number of events for selected targets \n",
    "events_day_list= []         # create a list with the selected index of the ID-list to make a balanced selection\n",
    "events_number_list = []\n",
    "events_day_list_shuffle = []\n",
    "for day in range(len(behaviour_list)):\n",
    "    \n",
    "    arg_min_target_time = np.argmin(number_of_events_list[day])\n",
    "    n_events = number_of_events_list[day][arg_min_target_time]\n",
    "    events_number_list.append(n_events)\n",
    "    events_list = []\n",
    "    events_list_copy = []\n",
    "    print('Number of events per day after balancing: ',n_events)\n",
    "    #print(n_events)\n",
    "    for target in range(len(events_id[day])):\n",
    "        sorted_events = np.sort(events_duration_list[day][target]) #sort of events\n",
    "        arg_sorted_events = np.argsort(events_duration_list[day][target]) #take the index sorted by duration of events\n",
    "        selected_events = arg_sorted_events[0:n_events]   # take only the first (sorter duration) events\n",
    "        events_list.append(selected_events)                           # save the position of long and balanced events\n",
    "        events_list_copy.append(selected_events.copy())               # make a copy of this events to create a shuffle list\n",
    "        \n",
    "    events_day_list.append(events_list)                              #this list contains index that are selected from the list of index of a specific target\n",
    "    events_day_list_shuffle.append(events_list_copy)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "daeed026-d062-45a4-a70d-04195595520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE SHUFFLE LABELS THAT PRESERVE BALANCE\n"
     ]
    }
   ],
   "source": [
    "print('CREATE SHUFFLE LABELS THAT PRESERVE BALANCE')\n",
    "\n",
    "### create shuffled behavioural labels that preserve balance and temporal structure\n",
    "### the shuffling will be in visits or events (so we shuffle the labels of the complete event)\n",
    "\n",
    "for day in range(len(behaviour_list)):\n",
    "    events_shuffle = []\n",
    "    events = np.array(events_day_list_1[day])\n",
    "    events_counter = np.array(events_counter_day_list[day])\n",
    "    events_time = np.array(events_time_starts_day[day])\n",
    "    arg_min_target_time = np.argmin(number_of_events_list[day])\n",
    "    n_events = number_of_events_list[day][arg_min_target_time]\n",
    "    \n",
    "    for target in range(len(events_id[day])):\n",
    "        #print(target)\n",
    "        #print(len(events_day_list[day]))\n",
    "        #print(events_day_list[day][target])\n",
    "        all_events = np.where(events == events_id[day][target])[0]\n",
    "        #print(len(all_events))\n",
    "        position_events = all_events[events_day_list[day][target]] # select the balanced data  \n",
    "        events_shuffle.append(position_events)\n",
    "    \n",
    "    for j in range(N_SHUFFLINGS):\n",
    "        counter_permutations = 0\n",
    "        for i in range(n_events):\n",
    "            permutation = np.random.permutation(len(events_id[day]))\n",
    "            #print(permutation)\n",
    "            counter_permutations +=1\n",
    "            for index in range(len(events_id[day])):\n",
    "                events_day_list_shuffle_1[day][j][events_shuffle[index][i]] = events_id[day][permutation[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "966ee6d8-db60-4a73-be61-b9bf927688b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAKING NEURAL OR TRANSFORMED ACTIVITY FOR EACH EVENT ... and create list with that\n"
     ]
    }
   ],
   "source": [
    "print('TAKING NEURAL OR TRANSFORMED ACTIVITY FOR EACH EVENT ... and create list with that')\n",
    "\n",
    "## put all events together and take neural activity from each event\n",
    "events_activity_pre_norm= []\n",
    "events_duration_list = []\n",
    "events_activity_pca = []\n",
    "events_activity_cca = []\n",
    "events_activity_cca2 = []\n",
    "events_activity_cca0 = []\n",
    "events_activity_lda = []\n",
    "\n",
    "\n",
    "for day in range(len(behaviour_list)):\n",
    "    target_activity = []\n",
    "    target_activity_pca = []\n",
    "    target_activity_cca = []\n",
    "    target_activity_cca2 = []\n",
    "    target_activity_cca0 = []\n",
    "    target_activity_lda = []\n",
    "    \n",
    "    events_duration_day = []\n",
    "    \n",
    "    events = np.array(events_day_list_1[day])\n",
    "    events_counter = np.array(events_counter_day_list[day])\n",
    "    events_time = np.array(events_time_starts_day[day])\n",
    "\n",
    "    for target in range(len(events_id[day])):\n",
    "        all_events = np.where(events == events_id[day][target])[0]\n",
    "        #print(all_events)\n",
    "        position_events = all_events[events_day_list[day][target]] ### this contains the balanced events\n",
    "        \n",
    "        events_duration = events_counter[position_events]   # convert to seconds\n",
    "        time = events_time[position_events]\n",
    "        i = 0\n",
    "        event_target = []\n",
    "        event_target_pca = []\n",
    "        event_target_cca = []\n",
    "        event_target_cca2 = []\n",
    "        event_target_cca0 = []\n",
    "        event_target_lda = []\n",
    "\n",
    "        #events_duration_target = np.zeros(len(events_duration),)\n",
    "        events_duration_target = []\n",
    "        for event in events_duration:\n",
    "            if event and time[i]-period >0 and time[i]+period < activity_list[day].shape[1]:\n",
    "                local_activity = activity_list[day][:,time[i]-period:time[i]+period]\n",
    "                local_activity_pca = activity_list_pca[day][:,time[i]-period:time[i]+period]\n",
    "                local_activity_cca = activity_list_cca[day][time[i]-period:time[i]+period,:].T\n",
    "                local_activity_cca2 = activity_list_cca2[day][time[i]-period:time[i]+period,:].T\n",
    "                local_activity_cca0 = activity_list_cca0[day][time[i]-period:time[i]+period,:].T\n",
    "                local_activity_lda = activity_list_lda[day][:,time[i]-period:time[i]+period]\n",
    "\n",
    "                event_target.append(local_activity)\n",
    "                event_target_pca.append(local_activity_pca)\n",
    "                event_target_cca.append(local_activity_cca)\n",
    "                event_target_cca2.append(local_activity_cca2)\n",
    "                event_target_cca2.append(local_activity_cca0)               \n",
    "                event_target_lda.append(local_activity_lda)\n",
    "                #events_duration_target[i]=1\n",
    "                events_duration_target.append(events_duration[i])\n",
    "            i = i + 1\n",
    "        target_activity.append(event_target)\n",
    "        target_activity_pca.append(event_target_pca)\n",
    "        target_activity_cca.append(event_target_cca)\n",
    "        target_activity_cca2.append(event_target_cca2)\n",
    "        target_activity_cca0.append(event_target_cca0)\n",
    "        target_activity_lda.append(event_target_lda)\n",
    "        events_duration_day.append(events_duration_target)\n",
    "        \n",
    "    events_activity_pre_norm.append(target_activity)\n",
    "    events_duration_list.append(events_duration_day)\n",
    "    events_activity_pca.append(target_activity_pca)\n",
    "    events_activity_cca.append(target_activity_cca)    \n",
    "    events_activity_cca2.append(target_activity_cca2)\n",
    "    events_activity_cca0.append(target_activity_cca0)    \n",
    "    events_activity_lda.append(target_activity_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4954771-e3ed-4ea5-b344-a452f96b39ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAKING NEURAL OR TRANSFORMED ACTIVITY FOR EACH EVENT ... and create list with that IN THE SHUFFLING DATA\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('TAKING NEURAL OR TRANSFORMED ACTIVITY FOR EACH EVENT ... and create list with that IN THE SHUFFLING DATA')\n",
    "\n",
    "### same but with the events shuffle data\n",
    "\n",
    "events_activity_pre_norm_shuffle= []\n",
    "events_activity_pca_shuffle = []\n",
    "events_activity_cca_shuffle = []\n",
    "events_activity_cca_shuffle2 = []\n",
    "events_activity_cca_shuffle0 = []\n",
    "events_activity_lda_shuffle = []\n",
    "\n",
    "for day in range(len(behaviour_list)):\n",
    "    \n",
    "    shufflings = []\n",
    "    shufflings_pca = []\n",
    "    shufflings_cca = []\n",
    "    shufflings_cca2 = []\n",
    "    shufflings_cca0 = []\n",
    "    shufflings_lda = []\n",
    "\n",
    "    for j in range(N_SHUFFLINGS):\n",
    "        target_activity_shuffle = []\n",
    "        target_activity_pca_shuffle = []\n",
    "        target_activity_cca_shuffle = []\n",
    "        target_activity_cca2_shuffle = []\n",
    "        target_activity_cca0_shuffle = []\n",
    "        target_activity_lda_shuffle = []\n",
    "        \n",
    "        events_duration_day_shuffle = []\n",
    "        for target in range(len(events_id[day])):\n",
    "            events = np.array(events_day_list_shuffle_1[day][j])\n",
    "            events_counter = np.array(events_counter_day_list[day])\n",
    "            events_time = np.array(events_time_starts_day[day])\n",
    "\n",
    "            all_events = np.where(events == events_id[day][target])[0]\n",
    "\n",
    "            #print(all_events)\n",
    "            #print(events_day_list[day][target])\n",
    "            position_events = all_events[events_day_list_shuffle[day][target]]\n",
    "\n",
    "            events_duration = events_counter[position_events]   # convert to seconds\n",
    "            time = events_time[position_events]\n",
    "            i = 0\n",
    "            event_target = []\n",
    "            event_target_pca = []\n",
    "            event_target_cca = []\n",
    "            event_target_cca2 = []\n",
    "            event_target_cca0 = []\n",
    "            event_target_lda = []\n",
    "\n",
    "            #events_duration_target = np.zeros(len(events_duration),)\n",
    "            events_duration_target = []\n",
    "            for event in events_duration:\n",
    "                if event and time[i]-period >0 and time[i]+period < activity_list[day].shape[1]:\n",
    "                    local_activity = activity_list[day][:,time[i]-period:time[i]+period]\n",
    "                    local_activity_pca = activity_list_pca[day][:,time[i]-period:time[i]+period]\n",
    "                    local_activity_cca = activity_list_cca[day][time[i]-period:time[i]+period,:].T\n",
    "                    local_activity_cca2 = activity_list_cca2[day][time[i]-period:time[i]+period,:].T\n",
    "                    local_activity_cca0 = activity_list_cca0[day][time[i]-period:time[i]+period,:].T\n",
    "                    local_activity_lda = activity_list_lda[day][:,time[i]-period:time[i]+period]\n",
    "\n",
    "                    event_target.append(local_activity)\n",
    "                    event_target_pca.append(local_activity_pca)\n",
    "                    event_target_cca.append(local_activity_cca)\n",
    "                    event_target_cca2.append(local_activity_cca2)\n",
    "                    event_target_cca0.append(local_activity_cca0)\n",
    "                    event_target_lda.append(local_activity_lda)\n",
    "\n",
    "                    #events_duration_target[i]=1\n",
    "                    events_duration_target.append(events_duration[i])\n",
    "                i = i + 1\n",
    "            target_activity_shuffle.append(event_target)\n",
    "            target_activity_pca_shuffle.append(event_target_pca)\n",
    "            target_activity_cca_shuffle.append(event_target_cca)\n",
    "            target_activity_cca2_shuffle.append(event_target_cca2)\n",
    "            target_activity_cca0_shuffle.append(event_target_cca0)\n",
    "            target_activity_lda_shuffle.append(event_target_lda)\n",
    "\n",
    "        shufflings.append(target_activity_shuffle)\n",
    "        shufflings_pca.append(target_activity_pca_shuffle)\n",
    "        shufflings_cca.append(target_activity_cca_shuffle)\n",
    "        shufflings_cca2.append(target_activity_cca2_shuffle)\n",
    "        shufflings_cca0.append(target_activity_cca0_shuffle)\n",
    "        shufflings_lda.append(target_activity_lda_shuffle)\n",
    "\n",
    "    events_activity_pre_norm_shuffle.append(shufflings)\n",
    "    events_activity_pca_shuffle.append(shufflings_pca)\n",
    "    events_activity_cca_shuffle.append(shufflings_cca)\n",
    "    events_activity_cca_shuffle2.append(shufflings_cca2)\n",
    "    events_activity_cca_shuffle0.append(shufflings_cca0)\n",
    "    events_activity_lda_shuffle.append(shufflings_lda)\n",
    "\n",
    "events_activity = events_activity_pre_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6f32ef47-2247-44d9-8dda-e1809aecb03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Trial matrices in all spaces for DAY = 0\n",
      "Target:0\n",
      "NUMBER OF VISITS:36\n",
      "Target:1\n",
      "NUMBER OF VISITS:36\n",
      "Target:2\n",
      "NUMBER OF VISITS:36\n",
      "Target:3\n",
      "NUMBER OF VISITS:36\n",
      "Computing Trial matrices in all spaces for SHUFFLINGS\n",
      "Computing representational distance in real data\n",
      "Computing representational distance in shuffling data\n",
      "Z-SCORING distances\n",
      "Saving...\n",
      "Computing Trial matrices in all spaces for DAY = 1\n",
      "Target:0\n",
      "NUMBER OF VISITS:9\n",
      "Target:1\n",
      "NUMBER OF VISITS:9\n",
      "Target:2\n",
      "NUMBER OF VISITS:9\n",
      "Target:3\n",
      "NUMBER OF VISITS:9\n",
      "Computing Trial matrices in all spaces for SHUFFLINGS\n",
      "Computing representational distance in real data\n",
      "Computing representational distance in shuffling data\n",
      "Z-SCORING distances\n",
      "Saving...\n",
      "Computing Trial matrices in all spaces for DAY = 2\n",
      "Target:0\n",
      "NUMBER OF VISITS:10\n",
      "Target:1\n",
      "NUMBER OF VISITS:10\n",
      "Target:2\n",
      "NUMBER OF VISITS:10\n",
      "Target:3\n",
      "NUMBER OF VISITS:10\n",
      "Computing Trial matrices in all spaces for SHUFFLINGS\n",
      "Computing representational distance in real data\n",
      "Computing representational distance in shuffling data\n",
      "Z-SCORING distances\n",
      "Saving...\n",
      "Computing Trial matrices in all spaces for DAY = 3\n",
      "Target:0\n",
      "NUMBER OF VISITS:26\n",
      "Target:1\n",
      "NUMBER OF VISITS:26\n",
      "Target:2\n",
      "NUMBER OF VISITS:26\n",
      "Target:3\n",
      "NUMBER OF VISITS:26\n",
      "Computing Trial matrices in all spaces for SHUFFLINGS\n",
      "Computing representational distance in real data\n",
      "Computing representational distance in shuffling data\n",
      "Z-SCORING distances\n",
      "Saving...\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "lda_components = 4\n",
    "for day in range(len(behaviour_list)): \n",
    "\n",
    "    print('Computing Trial matrices in all spaces for DAY = ' + str(day) )\n",
    "    trial_activity_vectors = np.zeros((len(events_id[day]),events_activity[day][0][0].shape[0],events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_pca_vectors = np.zeros((len(events_id[day]),events_activity[day][0][0].shape[0],events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_cca_vectors = np.zeros((len(events_id[day]),cca_components,events_activity[day][0][0].shape[1])) \n",
    "    trial_activity_cca_vectors2 = np.zeros((len(events_id[day]),cca_components2,events_activity[day][0][0].shape[1])) \n",
    "    trial_activity_lda_vectors = np.zeros((len(events_id[day]),lda_components,events_activity[day][0][0].shape[1])) \n",
    "\n",
    "    j= 0    \n",
    "    for target in range(len(events_id[day])):\n",
    "        # real data! \n",
    "        print('Target:' + str(target))\n",
    "        print('NUMBER OF VISITS:' + str(len(events_activity[day][target])))\n",
    "\n",
    "        if events_activity[day][target] != []:\n",
    "\n",
    "            trial_activity = np.zeros((events_activity[day][target][0].shape[0],events_activity[day][target][0].shape[1]))\n",
    "            trial_activity_pca = np.zeros((events_activity[day][target][0].shape[0],events_activity[day][target][0].shape[1]))\n",
    "            trial_activity_cca = np.zeros((cca_components,events_activity[day][target][0].shape[1]))\n",
    "            trial_activity_cca2 = np.zeros((cca_components2,events_activity[day][target][0].shape[1]))\n",
    "            trial_activity_lda = np.zeros((lda_components,events_activity[day][target][0].shape[1]))\n",
    "\n",
    "            ### generate matrix with mean activity and entire trial repetitions activity\n",
    "            for neuron in range(events_activity[day][target][0].shape[0]):\n",
    "                neuron_trial_activity = np.zeros((events_activity[day][target][1].shape[1],))\n",
    "                component_trial_activity = np.zeros((events_activity[day][target][0].shape[1],))\n",
    "                cca_trial_activity = np.zeros((events_activity[day][target][0].shape[1],))\n",
    "                cca_trial_activity2 = np.zeros((events_activity[day][target][0].shape[1],))\n",
    "                lda_trial_activity = np.zeros((events_activity[day][target][0].shape[1],))\n",
    "                for trial in range(len(events_activity[day][target])):\n",
    "                    if len(events_activity[day][target][trial][neuron,:]):\n",
    "                        neuron_trial_activity += events_activity[day][target][trial][neuron,:]#/(np.max(events_activity[day][target][trial][neuron,:])-np.min(events_activity[day][target][trial][neuron,:]))\n",
    "                        component_trial_activity +=events_activity_pca[day][target][trial][neuron,:]\n",
    "                        if neuron < cca_components:\n",
    "                            cca_trial_activity +=events_activity_cca[day][target][trial][neuron,:]\n",
    "                        if neuron < cca_components2:\n",
    "                            cca_trial_activity2 +=events_activity_cca2[day][target][trial][neuron,:]\n",
    "                        if neuron < lda_components:\n",
    "                            lda_trial_activity +=events_activity_lda[day][target][trial][neuron,:]      \n",
    "                neuron_trial_activity = neuron_trial_activity / len(events_activity[day][target])\n",
    "                component_trial_activity = component_trial_activity / len(events_activity[day][target])\n",
    "                trial_activity[neuron,:] = neuron_trial_activity\n",
    "                trial_activity_pca[neuron,:] = component_trial_activity\n",
    "                if neuron < cca_components:\n",
    "                    trial_activity_cca[neuron,:] = cca_trial_activity / cca_components\n",
    "                if neuron < cca_components2:\n",
    "                    trial_activity_cca2[neuron,:] = cca_trial_activity2 / cca_components2\n",
    "                if neuron < lda_components:\n",
    "                    trial_activity_lda[neuron,:] = lda_trial_activity / lda_components\n",
    "\n",
    "        trial_activity_vectors[j,:,:] = trial_activity\n",
    "        trial_activity_pca_vectors[j,:,:] = trial_activity_pca\n",
    "        trial_activity_cca_vectors[j,:,:] = trial_activity_cca[:cca_components,:]\n",
    "        trial_activity_cca_vectors2[j,:,:] = trial_activity_cca2[:cca_components2,:]\n",
    "        trial_activity_lda_vectors[j,:,:] = trial_activity_lda[:lda_components,:]\n",
    "\n",
    "\n",
    "        j= j+1            \n",
    "    print('Computing Trial matrices in all spaces for SHUFFLINGS')                \n",
    "    trial_activity_vectors_shuffle = np.zeros((N_SHUFFLINGS,len(events_id[day]),events_activity[day][0][0].shape[0],events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_pca_vectors_shuffle = np.zeros((N_SHUFFLINGS,len(events_id[day]),events_activity[day][0][0].shape[0],events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_cca_vectors_shuffle = np.zeros((N_SHUFFLINGS,len(events_id[day]),cca_components,events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_cca_vectors_shuffle2 = np.zeros((N_SHUFFLINGS,len(events_id[day]),cca_components2,events_activity[day][0][0].shape[1]))\n",
    "    trial_activity_lda_vectors_shuffle = np.zeros((N_SHUFFLINGS,len(events_id[day]),lda_components,events_activity[day][0][0].shape[1]))\n",
    "\n",
    "    for shuffle in range(N_SHUFFLINGS):\n",
    "        j=0\n",
    "        for target in range(len(events_id[day])):\n",
    "            trial_activity = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[0],events_activity_pre_norm_shuffle[day][shuffle ][target][0].shape[1]))\n",
    "            trial_activity_pca = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[0],events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1]))\n",
    "            trial_activity_cca = np.zeros((cca_components,events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1]))\n",
    "            trial_activity_cca2 = np.zeros((cca_components2,events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1]))\n",
    "            trial_activity_lda = np.zeros((lda_components,events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1]))\n",
    "\n",
    "            ### generate matrix with mean activity and entire trial repetitions activity\n",
    "            for neuron in range(events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[0]):\n",
    "                neuron_trial_activity = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1],))\n",
    "                component_trial_activity = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1],))\n",
    "                cca_trial_activity = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1],))\n",
    "                cca_trial_activity2 = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1],))\n",
    "                lda_trial_activity = np.zeros((events_activity_pre_norm_shuffle[day][shuffle][target][0].shape[1],))\n",
    "                for trial in range(len(events_activity_pre_norm_shuffle[day][shuffle][target])):\n",
    "                    if len(events_activity_pre_norm_shuffle[day][shuffle][target][trial][neuron,:]):\n",
    "                        neuron_trial_activity += events_activity_pre_norm_shuffle[day][shuffle][target][trial][neuron,:]#/(np.max(events_activity[day][target][trial][neuron,:])-np.min(events_activity[day][target][trial][neuron,:]))\n",
    "                        component_trial_activity +=events_activity_pca_shuffle[day][shuffle][target][trial][neuron,:]\n",
    "                        if neuron < cca_components:\n",
    "                            cca_trial_activity +=events_activity_cca_shuffle[day][shuffle][target][trial][neuron,:]\n",
    "                        if neuron < cca_components2:\n",
    "                            cca_trial_activity2 +=events_activity_cca_shuffle2[day][shuffle][target][trial][neuron,:]\n",
    "                        if neuron < lda_components:\n",
    "                            lda_trial_activity +=events_activity_lda_shuffle[day][shuffle][target][trial][neuron,:]\n",
    "\n",
    "                neuron_trial_activity = neuron_trial_activity / len(events_activity_pre_norm_shuffle[day][shuffle][target])\n",
    "                component_trial_activity = component_trial_activity / len(events_activity_pre_norm_shuffle[day][shuffle][target])\n",
    "                trial_activity[neuron,:] = neuron_trial_activity\n",
    "                trial_activity_pca[neuron,:] = component_trial_activity\n",
    "                if neuron < cca_components:\n",
    "                    trial_activity_cca[neuron,:] = cca_trial_activity / cca_components\n",
    "                if neuron < cca_components2:\n",
    "                    trial_activity_cca2[neuron,:] = cca_trial_activity2 / cca_components\n",
    "                if neuron < lda_components:\n",
    "                    trial_activity_lda[neuron,:] = lda_trial_activity / lda_components\n",
    "\n",
    "            trial_activity_vectors_shuffle[shuffle,j,:,:] = trial_activity\n",
    "            trial_activity_pca_vectors_shuffle[shuffle,j,:,:] = trial_activity_pca\n",
    "            trial_activity_cca_vectors_shuffle[shuffle,j,:,:] = trial_activity_cca[:cca_components,:]\n",
    "            trial_activity_cca_vectors_shuffle2[shuffle,j,:,:] = trial_activity_cca2[:cca_components2,:]\n",
    "            trial_activity_lda_vectors_shuffle[shuffle,j,:,:] = trial_activity_lda[:lda_components,:]\n",
    "            j=j+1\n",
    "\n",
    "\n",
    "    print('Computing representational distance in real data')\n",
    "    distance_neural = np.zeros((trial_activity_pca_vectors.shape[2],))\n",
    "    distance_pca = np.zeros((trial_activity_pca_vectors.shape[2],))\n",
    "    distance_cca = np.zeros((trial_activity_cca_vectors.shape[2],))\n",
    "    distance_cca2 = np.zeros((trial_activity_cca_vectors2.shape[2],))\n",
    "    distance_lda = np.zeros((trial_activity_cca_vectors.shape[2],))\n",
    "\n",
    "    pca_components = np.where(variance_ratio_list[day]>0.6)[0][0]\n",
    "\n",
    "    for time in range(trial_activity_vectors.shape[2]):\n",
    "        counter = 0\n",
    "        for i in range(trial_activity_pca_vectors.shape[0]):\n",
    "            for j in range(i+1,trial_activity_pca_vectors.shape[0]):\n",
    "                distance_neural[time] += np.linalg.norm(trial_activity_vectors[i,:,time] - trial_activity_vectors[j,:,time])\n",
    "                distance_pca[time] += np.linalg.norm(trial_activity_pca_vectors[i,0:pca_components,time] - trial_activity_pca_vectors[j,0:pca_components,time])\n",
    "                distance_cca[time] += np.linalg.norm(trial_activity_cca_vectors[i,:,time] - trial_activity_cca_vectors[j,:,time])\n",
    "                distance_cca2[time] += np.linalg.norm(trial_activity_cca_vectors2[i,:,time] - trial_activity_cca_vectors2[j,:,time])\n",
    "                distance_lda[time] += np.linalg.norm(trial_activity_lda_vectors[i,:,time] - trial_activity_lda_vectors[j,:,time])\n",
    "\n",
    "                counter+=1\n",
    "\n",
    "        distance_neural[time] = distance_neural[time]/counter\n",
    "        distance_pca[time] = distance_pca[time]/counter\n",
    "        distance_cca[time] = distance_cca[time]/counter\n",
    "        distance_cca2[time] = distance_cca2[time]/counter\n",
    "        distance_lda[time] = distance_lda[time]/counter\n",
    "\n",
    "    print('Computing representational distance in shuffling data')\n",
    "\n",
    "    distance_neural_shuffle = np.zeros((N_SHUFFLINGS,trial_activity_vectors.shape[2],))\n",
    "    distance_pca_shuffle = np.zeros((N_SHUFFLINGS,trial_activity_vectors.shape[2],))\n",
    "    distance_cca_shuffle = np.zeros((N_SHUFFLINGS,trial_activity_vectors.shape[2],))\n",
    "    distance_cca_shuffle2 = np.zeros((N_SHUFFLINGS,trial_activity_vectors.shape[2],))\n",
    "    distance_lda_shuffle = np.zeros((N_SHUFFLINGS,trial_activity_vectors.shape[2],))\n",
    "\n",
    "    for shuffle in range(N_SHUFFLINGS):\n",
    "        for time in range(trial_activity_vectors.shape[2]):\n",
    "            counter = 0\n",
    "            for i in range(trial_activity_pca_vectors_shuffle.shape[1]):\n",
    "                for j in range(i+1,trial_activity_pca_vectors_shuffle.shape[1]):\n",
    "                    distance_neural_shuffle[shuffle,time] += np.linalg.norm(trial_activity_vectors_shuffle[shuffle,i,:,time] - trial_activity_vectors_shuffle[shuffle,j,:,time])\n",
    "                    distance_pca_shuffle[shuffle,time] += np.linalg.norm(trial_activity_pca_vectors_shuffle[shuffle,i,0:pca_components,time] - trial_activity_pca_vectors_shuffle[shuffle,j,0:pca_components,time])\n",
    "                    distance_cca_shuffle[shuffle,time] += np.linalg.norm(trial_activity_cca_vectors_shuffle[shuffle,i,:,time] - trial_activity_cca_vectors_shuffle[shuffle,j,:,time])\n",
    "                    distance_cca_shuffle2[shuffle,time] += np.linalg.norm(trial_activity_cca_vectors_shuffle2[shuffle,i,:,time] - trial_activity_cca_vectors_shuffle2[shuffle,j,:,time])\n",
    "                    distance_lda_shuffle[shuffle,time] += np.linalg.norm(trial_activity_lda_vectors_shuffle[shuffle,i,:,time] - trial_activity_lda_vectors_shuffle[shuffle,j,:,time])\n",
    "                    counter = counter +1\n",
    "            distance_neural_shuffle[shuffle,time] = distance_neural_shuffle[shuffle,time]/counter\n",
    "            distance_pca_shuffle[shuffle,time] = distance_pca_shuffle[shuffle,time]/counter\n",
    "            distance_cca_shuffle[shuffle,time] = distance_cca_shuffle[shuffle,time]/counter\n",
    "            distance_cca_shuffle2[shuffle,time] = distance_cca_shuffle2[shuffle,time]/counter\n",
    "            distance_lda_shuffle[shuffle,time] = distance_lda_shuffle[shuffle,time]/counter\n",
    "\n",
    "    distance_mean = np.mean(distance_neural_shuffle,axis=0)\n",
    "    distance_pca_mean = np.mean(distance_pca_shuffle,axis=0)\n",
    "    distance_cca_mean = np.mean(distance_cca_shuffle,axis=0)\n",
    "    distance_cca_mean2 = np.mean(distance_cca_shuffle2,axis=0)\n",
    "    distance_lda_mean = np.mean(distance_lda_shuffle,axis=0)\n",
    "\n",
    "    distance_std = np.std(distance_neural_shuffle,axis=0)\n",
    "    distance_pca_std = np.std(distance_pca_shuffle,axis=0)\n",
    "    distance_cca_std = np.std(distance_cca_shuffle,axis=0) \n",
    "    distance_cca_std2 = np.std(distance_cca_shuffle2,axis=0) \n",
    "    distance_lda_std = np.std(distance_lda_shuffle,axis=0)\n",
    "\n",
    "    print('Z-SCORING distances')\n",
    "    z_scored_neural = (distance_neural - distance_mean)/distance_std\n",
    "    z_scored_pca = (distance_pca - distance_pca_mean)/distance_pca_std\n",
    "    z_scored_cca = (distance_cca - distance_cca_mean)/distance_cca_std\n",
    "    z_scored_cca2 = (distance_cca2 - distance_cca_mean2)/distance_cca_std\n",
    "    z_scored_lda = (distance_lda - distance_lda_mean)/distance_lda_std\n",
    "\n",
    "    final_distance = np.zeros((5, len(z_scored_neural)))\n",
    "    final_distance[0,:] = z_scored_neural\n",
    "    final_distance[1,:] = z_scored_pca\n",
    "    final_distance[2,:] = z_scored_cca\n",
    "    final_distance[3,:] = z_scored_cca2\n",
    "    final_distance[4,:] = z_scored_lda\n",
    "\n",
    "    print('Saving...')\n",
    "    output_path =  os.environ['PROJECT_DIR'] +'neural_analysis/data/mean_representational_distance/'\n",
    "    file_name = output_path  +'corners_position_distance_2_mouse_'+f'{mouse}'+'_session_'+f'{session}'+ '_day_'+f'{day}'\n",
    "    np.save(file_name, final_distance)\n",
    "\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532777c3-6658-4a40-b7bc-52f840f0a67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478b8808-d635-4a2f-a177-0ebb6005b862",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20924cc-c9f7-4404-b497-1c593772319f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463a79d-da9e-49f8-bfcb-2b2ee6dc1917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
