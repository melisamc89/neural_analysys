{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Population vector analysis \n",
    "\n",
    "'''Created on Thu 27 Aug 2020'''\n",
    "\n",
    "In this notebook we will analyze the population vector for different behaviours of the mouse and different object explorations. \n",
    "The general analysis can be implemented in the differents types of preprocessing (day wise, with registration trial wise or day wise) but we will focus in different day analysis. \n",
    "In this experiement we have 4 traning days and one testing, so we will organize the data in order to use those multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import configuration\n",
    "import general_statistics as stats\n",
    "import figures as figs\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from scipy import signal\n",
    "from scipy import stats as sstats\n",
    "import scipy\n",
    "cmap = cm.jet\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mouse information, and preprocessin versions from analysis.\n",
    "# load data for all sessions in this mouse and compute mean activity for each neuron.\n",
    "\n",
    "mouse = 56165           ### mouse number id\n",
    "decoding_v = 1            ## decoding version, normaly equal to one\n",
    "motion_correction_v = 20  ### 100 means everything was aligned, 200 means it was also equalized, 20 is for day wise\n",
    "alignment_v = 3           ## alignment version, version 3 is for day wise\n",
    "equalization_v = 0        ## equalization version\n",
    "source_extraction_v = 1   ## source extraction version\n",
    "component_evaluation_v = 1 ## component evaluation version\n",
    "\n",
    "# here we will do analysis with no registration\n",
    "# registration_v = 2        ## registration version\n",
    "sf = 10                   ## sampling frequency of the original signal \n",
    "re_sf= 10                 ## value of resampling\n",
    "session_now = 2\n",
    "period = 6\n",
    "fixed = 'None'\n",
    "## define task for plotting. This will cahnge for other mice!!!!\n",
    "if mouse == 56165 or mouse == 32364:\n",
    "    if mouse == 56165:\n",
    "        sessions = [1,2,4]       ## sessions for this particular mouse\n",
    "    if mouse == 32364:\n",
    "        sessions = [1,2]\n",
    "    if session_now == 1:\n",
    "        task = 'OVERLAPPING'\n",
    "        if mouse == 32364:\n",
    "            fixed = 'LR'\n",
    "        if mouse == 56165:\n",
    "            fixed = 'UR'\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'STABLE'\n",
    "            if mouse == 32364:\n",
    "                fixed = 'UL and UR'\n",
    "            if mouse == 56165:\n",
    "                fixed = 'UR and LR (verify)'\n",
    "        else:\n",
    "            task = 'RANDOM'\n",
    "            \n",
    "if mouse == 32365:\n",
    "    sessions = [2,3] ## sessions for this particular mouse\n",
    "    if session_now == 2:\n",
    "        task = 'RANDOM'\n",
    "    else:\n",
    "        if session_now == 3:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'LR'\n",
    "            \n",
    "if mouse == 56166:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UL'\n",
    "            \n",
    "if mouse == 32366:\n",
    "    sessions = [3,3] ## sessions for this particular mouse\n",
    "    if session_now == 3:\n",
    "        task = 'RANDOM'\n",
    "            \n",
    "if mouse == 32363:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = os.environ['PROJECT_DIR'] + 'neural_analysis/data/calcium_activity_day_wise/'\n",
    "timeline_file_dir = os.environ['PROJECT_DIR'] + 'neural_analysis/data/timeline/'\n",
    "behaviour_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/scoring_time_vector/'\n",
    "objects_dir= os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/object_positions/'\n",
    "figure_path = os.environ['PROJECT_DIR'] +'neural_analysis/data/process/figures/population_analysis/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all relevant files names and load them into a list\n",
    "session = session_now\n",
    "\n",
    "activity_list = []\n",
    "timeline_list = []\n",
    "behaviour_list = []\n",
    "day = 1\n",
    "for trial in [1,6,11,16,21]:\n",
    "    file_name_session_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_trial_'+ f'{trial}'+'_v' + f'{decoding_v}' + '.4.' + f'{motion_correction_v}' + \\\n",
    "                          '.' + f'{alignment_v}' + '.' + f'{equalization_v}' + '.' + f'{source_extraction_v}' + '.' + \\\n",
    "                          f'{component_evaluation_v}' +  '.1.npy'\n",
    "\n",
    "    ##load activity and timeline\n",
    "    activity = np.load(file_directory + file_name_session_1)\n",
    "    neural_activity1 = activity[1:,:]\n",
    "    ## z-score neural activity\n",
    "    neural_activity = sstats.zscore(neural_activity1)\n",
    "    \n",
    "    ##downsample neural activity\n",
    "    resample_neural_activity_mean, resample_neural_activity_std = stats.resample_matrix(neural_activity=neural_activity,\n",
    "                                                                                        re_sf=re_sf)\n",
    "    \n",
    "    activity_list.append(resample_neural_activity_mean)\n",
    "    \n",
    "    time_file_session_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_trial_1_v' + f'{decoding_v}' + '.4.' + f'{1}' + \\\n",
    "                          '.' + f'{0}' + '_10.pkl'\n",
    "    timeline_file = open(timeline_file_dir + time_file_session_1, 'rb')\n",
    "    timeline_info = pickle.load(timeline_file)\n",
    "    ##normalize neural activity\n",
    "    timeline_1 = np.zeros(len(timeline_info) + 1)\n",
    "    for i in range(len(timeline_info)):\n",
    "        timeline_1[i] = timeline_info[i][1]\n",
    "    timeline_1[len(timeline_info)] = activity.shape[1]\n",
    "    resample_timeline = timeline_1/re_sf\n",
    "\n",
    "    timeline_list.append(resample_timeline)\n",
    "    \n",
    "    beh_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' +'_day_'+f'{day}'+'_event_' + f'{re_sf}' + '.npy'\n",
    "    ## LOAD BEHAVIOUR\n",
    "    behaviour = np.load(behaviour_dir + beh_file_name_1)\n",
    "    #c = np.linspace(0, 20, len(behaviour))\n",
    "    reshape_behaviour = np.reshape(behaviour[:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "    resample_beh1 = np.reshape(scipy.stats.mode(reshape_behaviour,axis=1)[0],reshape_behaviour.shape[0])\n",
    "    resample_timeline = timeline_1/re_sf\n",
    "    \n",
    "    behaviour_list.append(resample_beh1)\n",
    "    day = day + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each day creates a list that counts and saves times of different events.\n",
    "# We will consider events here as resting period, navigation periods and object exploration periods.\n",
    "# Later on will also consider different objects in the exploration periods\n",
    "\n",
    "events_day_list = []\n",
    "events_counter_day_list = []\n",
    "events_time_starts_day = []\n",
    "for day in range(len(behaviour_list)):\n",
    "    events_list = []\n",
    "    events_counter_list = []\n",
    "    events_time_starts = []\n",
    "    start_counter = 100\n",
    "    counter = 0\n",
    "    for i in range(behaviour_list[day].shape[0]):\n",
    "        if behaviour_list[day][i] != start_counter:\n",
    "            events_list.append(start_counter)\n",
    "            events_counter_list.append(counter)\n",
    "            events_time_starts.append(i)\n",
    "            start_counter = behaviour_list[day][i]\n",
    "            counter = 1\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    events_day_list.append(events_list)\n",
    "    events_counter_day_list.append(events_counter_list)\n",
    "    events_time_starts_day.append(events_time_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separte events belonging to each of the behavioural conditions\n",
    "\n",
    "behavioural_events_days_list = []\n",
    "conditions = [ 'Resting', 'Navigation', 'Object_exploration']\n",
    "\n",
    "for day in range(len(behaviour_list)):\n",
    "    events = np.array(events_day_list[day])\n",
    "    events[np.where(events>1)] = 2\n",
    "    events_counter = np.array(events_counter_day_list[day])\n",
    "    events_time = np.array(events_time_starts_day[day])\n",
    "\n",
    "    object_list = []\n",
    "    for target in [0,1,2]:\n",
    "        object_data = []\n",
    "        position_events = np.where(events == target)[0]\n",
    "        events_duration = events_counter[position_events]   # convert to seconds\n",
    "        time = events_time[position_events]\n",
    "        i = 0\n",
    "        for event in events_duration:\n",
    "            if event > period:\n",
    "                object_data.append(activity_list[day][:,time[i]:time[i]+period])\n",
    "            i = i + 1\n",
    "        object_list.append(object_data)\n",
    "    behavioural_events_days_list.append(object_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to here, we created a list (behavioural_events_days_list) that has 5 elements corresponding to each day\n",
    "Each element of the list, is itself a list, containing three new elements that are related to different behaviours\n",
    "and each list for each behavior is a list of activity (calcium trace) matrix of size number of neurons X period.\n",
    "where period is a variable we can choose.\n",
    "\n",
    "As number of neurons is different for each day, we will compare behavioural conditions within a day. \n",
    "\n",
    "Lets now compute the population vector for the three behavioural conditions, and plot it for different days.\n",
    "Population vector here will be the mean over the period of time choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_vector = []\n",
    "for day in range(len(behaviour_list)):\n",
    "    mean_over_trials_list = []\n",
    "    for i in range(len(behavioural_events_days_list[day])):\n",
    "        mean_over_trials= np.mean(behavioural_events_days_list[day][i], axis= 0)\n",
    "        if mean_over_trials.shape:\n",
    "            mean_over_trials_list.append(np.mean(mean_over_trials,axis=1))#/np.max(np.mean(mean_over_trials,axis=1)))\n",
    "    population_vector.append(mean_over_trials_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute null hypotesis for euclidean distance\n",
    "\n",
    "# we compute for each day a matrix containing all the activity\n",
    "matrix = []\n",
    "matrix_elements_size= []\n",
    "for day in range(len(behavioural_events_days_list)):\n",
    "    matrix_list = []\n",
    "    matrix_size = 0\n",
    "    matrix_limits = []\n",
    "    for i in range(len(behavioural_events_days_list[day])):\n",
    "        if behavioural_events_days_list[day][i]: \n",
    "            mean_over_trials =  np.mean(behavioural_events_days_list[day][i], axis= 0)            \n",
    "            matrix1 = np.zeros((len(mean_over_trials),period*len(behavioural_events_days_list[day][i])))\n",
    "            for j in range(len(behavioural_events_days_list[day][i])):\n",
    "                matrix1[:,j*period:(j+1)*period] = behavioural_events_days_list[day][i][j]\n",
    "            matrix_list.append(matrix1)\n",
    "            matrix_limits.append([matrix_size, matrix_size + period*len(behavioural_events_days_list[day][i])])\n",
    "            matrix_size = matrix_size + period*len(behavioural_events_days_list[day][i])\n",
    "    auxiliar_matrix = np.zeros((len(mean_over_trials),matrix_size))\n",
    "    for i in range(len(matrix_list)):\n",
    "        auxiliar_matrix[:,matrix_limits[i][0]:matrix_limits[i][1]] = matrix_list[i]\n",
    "    matrix.append(auxiliar_matrix)\n",
    "    matrix_elements_size.append(matrix_limits)\n",
    "\n",
    "\n",
    "## compute null distribution of distances over randomly selected group of bins\n",
    "n_shufflings = 1000\n",
    "null_distribution_list = []\n",
    "for day in range(len(behavioural_events_days_list)):\n",
    "    data = matrix[day]\n",
    "    null_distribution = []\n",
    "    for i in range(n_shufflings):\n",
    "        random_order = np.random.randint(0,data.shape[1],data.shape[1])\n",
    "        mean_list = []\n",
    "        for j in range(len(matrix_elements_size[day])):\n",
    "            random_values = random_order[matrix_elements_size[day][j][0]:matrix_elements_size[day][j][1]]\n",
    "            mean_vector = np.mean(matrix[day][:,random_values])\n",
    "            mean_list.append(mean_vector)\n",
    "        for j in range(len(mean_list)):\n",
    "            for k in range(j+1,len(mean_list)):\n",
    "                distance = np.linalg.norm(mean_list[j]-mean_list[k])\n",
    "                null_distribution.append(distance)\n",
    "    null_distribution_list.append(null_distribution)         \n",
    "    \n",
    "## plot null distribution for different days\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = plt.GridSpec(1,5)\n",
    "for day in range(len(null_distribution_list)):\n",
    "    ax = fig.add_subplot(gs[0, day])\n",
    "    ax.hist(null_distribution_list[day])\n",
    "    \n",
    "## sort null distribution values and take 95%\n",
    "null_distribution_limit = []\n",
    "for day in range(len(null_distribution_list)):\n",
    "    sorted_null_distribution = np.sort(null_distribution_list[day])\n",
    "    null_distribution_limit.append(sorted_null_distribution[950])   \n",
    "print(null_distribution_limit)\n",
    "    \n",
    "## compute euclidean distance matrix using normalization\n",
    "euclidean_distance_list = []\n",
    "for day in range(len(behaviour_list)-1):\n",
    "    euclidean_distance = np.zeros((len(population_vector[day]),len(population_vector[day])))\n",
    "    for i in range(len(population_vector[day])):\n",
    "        for j in range(len(population_vector[day])):\n",
    "            distance = np.linalg.norm(population_vector[day][i]-population_vector[day][j])\n",
    "            euclidean_distance[i,j]= distance / population_vector[day][i].shape\n",
    "    euclidean_distance_list.append(euclidean_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = plt.GridSpec(len(behaviour_list)-1, 6)\n",
    "\n",
    "vmin= 0\n",
    "vmax=0.03\n",
    "\n",
    "for day in range(len(behaviour_list)-1):\n",
    "    ax = fig.add_subplot(gs[day, 0:4])\n",
    "    \n",
    "    ax.plot(population_vector[day][0])\n",
    "    ax.plot(population_vector[day][1])\n",
    "    ax.plot(population_vector[day][2])\n",
    "    \n",
    "    ax.legend(conditions, fontsize = 12)\n",
    "    if day == len(behaviour_list)-2:\n",
    "        ax.set_xlabel('Neurons', fontsize = 20)\n",
    "    ax.set_ylabel('Mean activation', fontsize = 15)\n",
    "    ax.set_title('Day = ' + f'{day+1}')\n",
    "    \n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[day, 5])\n",
    "    if day == 0:\n",
    "        ax1.set_title('Euclidean distance', fontsize = 15)\n",
    "    x = ax1.imshow(euclidean_distance_list[day], cmap = 'gray')\n",
    "    #x = ax.pcolormesh(euclidean_distance_list[day], cmap = 'gray')\n",
    "    x.set_clim(vmin,vmax)\n",
    "    \n",
    "    x_pos = np.arange(-0.5,len(conditions)+0.5)\n",
    "    ax1.set_yticks(x_pos)\n",
    "    ax1.set_yticklabels(conditions)\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels([])\n",
    "    if day == len(behaviour_list)-2:\n",
    "        ax1.set_xticks(x_pos)\n",
    "        ax1.set_xticklabels(conditions)\n",
    "        ax1.set_xlabel('Conditions', fontsize = 12)\n",
    "    ax1.set_ylabel('Conditions', fontsize = 12)\n",
    "    \n",
    "    plt.setp(ax1.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    fig.colorbar(x, ax=ax1)\n",
    "\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15,10)\n",
    "fig.suptitle('Population Vector differences: ' + task + ' fixed = ' + fixed  , fontsize = 25)\n",
    "\n",
    "figure_name = figure_path +'population_vector_events_mouse_'+f'{mouse}'+'_session_'+f'{session}'+\\\n",
    "                             '_binsize_'+f'{re_sf}'+'_period_'+ f'{period}'  +'.png'\n",
    "fig.savefig(figure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
