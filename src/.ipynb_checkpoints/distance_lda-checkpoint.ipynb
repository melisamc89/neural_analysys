{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dfb8a1f-9288-4007-8618-e0f8c49df1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import configuration\n",
    "import general_statistics as stats\n",
    "import figures as figs\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from scipy import signal\n",
    "from scipy import stats as sstats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy\n",
    "cmap = cm.jet\n",
    "import math\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import random\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from analysis_functions import *\n",
    "\n",
    "\n",
    "def transform_neural_data_lda(activity_list, behaviour_list,parameters_time,parameters_list,parameters_list2,timeline,trial_list, trial_flag = False):\n",
    "    \n",
    "    day = 0\n",
    "    clf = LDA()\n",
    "    activity_list_lda = []\n",
    "    \n",
    "    if trial_flag:  \n",
    "        activity_list_lda_trial = []\n",
    "        trial_list_new_trial= np.zeros((20,))\n",
    "        \n",
    "    trial_list_new = np.zeros_like(trial_list)\n",
    "    for day in range(len(trial_list)):\n",
    "        if trial_list[day]:\n",
    "            if activity_list[day].shape[1] == behaviour_list[day].shape[0]:\n",
    "                trial_list_new[day] = trial_list[day]\n",
    "                ### run pca on the entire dataset\n",
    "                X = activity_list[day].T\n",
    "                y = behaviour_list[day]\n",
    "                X_transformed = clf.fit(X, y).transform(X)\n",
    "                #X_lda_transformed = embedding.fit_transform(X_transformed.T)\n",
    "                activity_list_lda.append(X_transformed.T)\n",
    "\n",
    "                if trial_flag:\n",
    "                    for i in range(5):\n",
    "                        time1 = int(timeline[day][2*i])\n",
    "                        time2 = int(timeline[day][2*i+1])\n",
    "                        time3 = int(timeline[day][2*(i+1)])\n",
    "                        trial_list_new_trial[day*5+i] = day*5+i+1\n",
    "                        activity_list_lda_trial.append(X_transformed[time1:time2,:].T)  \n",
    "            else:\n",
    "                trial_list_new[day] = 0\n",
    "                activity_list_lda.append([])\n",
    "                \n",
    "                if trial_flag:\n",
    "                    for i in range(5):\n",
    "                        trial_list_new_trial[day*5+i] = 0\n",
    "                        activity_list_lda_trial.append([]) \n",
    "        else:\n",
    "            if trial_flag:\n",
    "                for i in range(5):\n",
    "                    trial_list_new_trial[day*5+i] = 0\n",
    "                    activity_list_lda_trial.append([]) \n",
    "            trial_list_new[day] = 0\n",
    "            activity_list_lda.append([])\n",
    "\n",
    "            continue\n",
    "    \n",
    "    data_transformation = namedtuple('data_transformation', ['lda','trials'])\n",
    "    if trial_flag:\n",
    "        return data_transformation(activity_list_lda_trial,trial_list_new_trial)\n",
    "    else:\n",
    "        return data_transformation(activity_list_lda,trial_list_new)\n",
    "    \n",
    "def create_trial_activity_list(activity_events,events_id,trial_list):\n",
    "    \n",
    "    trial_activity_lda,new_list = create_visits_matrix(activity_events.lda,events_id,trial_list)\n",
    "\n",
    "    trial_activity = namedtuple('trial_activity', ['lda','trials'])    \n",
    "    return trial_activity(trial_activity_lda,new_list)\n",
    "\n",
    "def create_trial_activity_list_shuffle(activity_events_shuffle,events_id, N_SHUFFLINGS,trial_list):\n",
    " \n",
    "    trial_activity_lda= create_visits_matrix_shufflings(activity_events_shuffle.lda,events_id,N_SHUFFLINGS,trial_list)\n",
    "    trial_activity_shuffle = namedtuple('trial_activity_shuffle', ['lda'])\n",
    "    return trial_activity_shuffle(trial_activity_lda)\n",
    "\n",
    "def create_events_data_transformation(activity_list,data_transformation,period,events,events_counter,events_onset,events_id,events_b,trial_list):\n",
    "\n",
    "    events_activity_lda, events_duration = create_activity_events(data_transformation.lda,period,events,events_counter,events_onset,events_id,events_b,trial_list)\n",
    "    \n",
    "    events = namedtuple('events', ['lda'])    \n",
    "    return events(events_activity_lda)\n",
    "\n",
    "def create_events_data_transformation_shuffling(activity_list,data_transformation,period,events_shuffle_b,events_counter,events_onset,events_id,events_s_b, N_SHUFFLINGS,trial_list):\n",
    "    \n",
    "    events_activity_shuffle_lda = create_activity_events_shuffle(data_transformation.lda,period,events_shuffle_b,events_counter,events_onset,events_id,events_s_b, N_SHUFFLINGS,trial_list)\n",
    "\n",
    "    events = namedtuple('events', ['lda'])    \n",
    "    return events(events_activity_shuffle_lda)\n",
    "    \n",
    "def compute_distance_lda(trial_activity, trial_activity_shuffle, data_transformation, N_SHUFFLINGS,trial_list,events_id,metric = 'Euclidean',trial_flag = False):\n",
    "    \n",
    "    lda_components = []\n",
    "    \n",
    "    for day in range(len(trial_activity.lda)):\n",
    "        if trial_list[day]:\n",
    "            print(day)\n",
    "            lda_components.append(trial_activity.lda[day].shape[1])\n",
    "        else:\n",
    "            lda_components.append([])\n",
    "\n",
    "    lda_min = 4\n",
    "    for i in range(len(lda_components)):\n",
    "        lda_components[i] = lda_min\n",
    "            \n",
    "    distance_lda, z_scored_lda = compute_representational_distance_all_to_all(trial_activity.lda,trial_activity_shuffle.lda,lda_components, N_SHUFFLINGS,trial_list,events_id,metric,trial_flag)\n",
    "\n",
    "    non_nan_z_scored_lda = np.nan_to_num( np.nansum([z_scored_lda,z_scored_lda.T],axis = 0),neginf=0)\n",
    "    \n",
    "    distance = namedtuple('distance', ['lda'])\n",
    "    return distance(non_nan_z_scored_lda)\n",
    "    \n",
    "\n",
    "def compute_distance(activity_list,data_transformation,period,behaviour_list,id_target,N_SHUFFLINGS,trial_list, metric = 'Euclidean',trial_flag = False):\n",
    "    \n",
    "    print('CREATE LIST THAT SAVES ALL THE EVENTS IN A DAY AND CONTAINS ONSET OF VISITS')\n",
    "    events_etho, events_shuffle_etho,events_counter_etho,events_onset_etho = create_events_list(behaviour_list, N_SHUFFLINGS,trial_list)\n",
    "    print('NOW WE SEPARATE EVENTS TYPES ACCORDING TO CORNER/OBJECT VISIT')\n",
    "    events_duration_etho, total_duration_etho,number_of_events_etho,events_id_etho = create_id_events(events_etho, events_counter_etho,events_onset_etho,id_target,trial_list)\n",
    "    print(number_of_events_etho)\n",
    "    print('BALANCING TO THE LOWER NUMBER OF VISITS')\n",
    "    events_number_etho, events_etho_b, events_etho_s_b = balancing_visits(number_of_events_etho,events_duration_etho,events_id_etho,trial_list)\n",
    "    print('CREATE SHUFFLE LABELS THAT PRESERVE BALANCE')\n",
    "    events_etho_shuffle_b = create_shuffling(events_etho,events_shuffle_etho,events_counter_etho,events_onset_etho,number_of_events_etho,events_id_etho,events_etho_b,N_SHUFFLINGS)\n",
    "    print(events_number_etho)\n",
    "    \n",
    "    print('TAKING NEURAL OR TRANSFORMED ACTIVITY FOR EACH EVENT ... and create list with that')\n",
    "    activity_events_etho = create_events_data_transformation(activity_list,data_transformation,period,events_etho,events_counter_etho,events_onset_etho,events_id_etho,events_etho_b,trial_list)\n",
    "    activity_events_etho_shuffling=create_events_data_transformation_shuffling(activity_list,data_transformation,period,events_etho_shuffle_b,events_counter_etho,events_onset_etho,events_id_etho,events_etho_s_b, N_SHUFFLINGS,trial_list)\n",
    "    \n",
    "    print('CREATING VISITIS ACTIVITY MATRICES')\n",
    "    trial_activity_etho = create_trial_activity_list(activity_events_etho,events_id_etho,trial_list)\n",
    "    trial_activity_shuffle_etho = create_trial_activity_list_shuffle(activity_events_etho_shuffling,events_id_etho, N_SHUFFLINGS,trial_list)\n",
    "    print('CREATING DISTANCE tuple')\n",
    "    #distance  = 0\n",
    "    distance = compute_distance_lda(trial_activity_etho,trial_activity_shuffle_etho, data_transformation, N_SHUFFLINGS,trial_activity_etho.trials, events_id_etho,metric, trial_flag)\n",
    "    \n",
    "    return trial_activity_etho, trial_activity_shuffle_etho , events_id_etho, distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0942a83-27dd-459e-b3d2-bf825de2e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_v = 1            ## decoding version, normaly equal to one\n",
    "motion_correction_v = 20  ### 100 means everything was aligned, 200 means it was also equalized, 20 is for day wise\n",
    "alignment_v = 3           ## alignment version, version 3 is for day wise\n",
    "equalization_v = 0        ## equalization version\n",
    "source_extraction_v = 1   ## source extraction version\n",
    "component_evaluation_v = 1 ## component evaluation version\n",
    "binary = False\n",
    "\n",
    "# here we will do analysis with no registration\n",
    "# registration_v = 2        ## registration version\n",
    "sf = 10                   ## sampling frequency of the original signal \n",
    "re_sf= 1                 ## value of resampling\n",
    "period = int(5 * sf / re_sf)\n",
    "period_resting = period *50\n",
    "N_SHUFFLINGS = 50\n",
    "colorcodes = ['Greys','PuBu', 'YlOrRd','Reds','Blues','Oranges','Greens']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25a5c00-8dfe-47f4-bd82-41ebb449ef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SESSION ==== 1\n",
      "LOADING TRIALS ACTIVITY AND CREATING LIST OF ACTIVITY, TRACKING AND BEHAVIOUR\n",
      "neural shape =  (124, 38103) beh shape(38103,)\n"
     ]
    }
   ],
   "source": [
    "# mouse_vector = [56165, 56166, 32363, 32364, 32365, 32366, 411857, 401714]\n",
    "# conditions_vector = ['RANDOM', 'OVERLAPPING','STABLE']\n",
    "# sessions_random = [4,1,1,0,2,3,2]\n",
    "# sessions_overlapping = [1,2,2,1,3,0,3]\n",
    "# sessions_stable = [2,0,0,2,0,0,1]\n",
    "\n",
    "# for mouse in mouse_vector: \n",
    "#     for session_now in \n",
    "mouse = 32363 ### mouse number id\n",
    "figure_path = os.environ['PROJECT_DIR'] +'neural_analysis/figures/trial_aligned_events/examples/'\n",
    "metric_use = 'euclidean'\n",
    "\n",
    "for session_now in range(1,2):\n",
    "    \n",
    "    print('SESSION ====', session_now)\n",
    "\n",
    "    file_directory = os.environ['PROJECT_DIR'] + 'neural_analysis/data/calcium_activity_day_wise/'\n",
    "    timeline_file_dir = os.environ['PROJECT_DIR'] + 'neural_analysis/data/timeline/'\n",
    "    behaviour_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/ethogram/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "    behaviour_dir_parameters = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/ethogram_parameters/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "    tracking_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/center_of_mass/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "    objects_dir= os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/object_positions/'\n",
    "    figure_path = os.environ['PROJECT_DIR'] +'neural_analysis/figures/trial_aligned_events/'\n",
    "\n",
    "    objects_position_file = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/occupied_corners/' + 'mouse_'+f'{mouse}'+'_session_'+f'{session_now}'+'.npy'\n",
    "    occupied_corners = np.load(objects_position_file)\n",
    "    task,colapse_behaviour,object_fixed,fixed,labels,colornames = mouse_properties(mouse = mouse, session_now = session_now)\n",
    "    ##### DAY TRANSFORMATIONS ####\n",
    "    activity_list,timeline_list,behaviour_list,corners_list,parameters_time,parameters_list,parameters_list2, speed_list, day_list,tracking_list= load_data(mouse, session_now,\n",
    "    decoding_v, motion_correction_v, alignment_v, equalization_v,source_extraction_v,component_evaluation_v, re_sf,file_directory, timeline_file_dir, behaviour_dir, behaviour_dir_parameters, tracking_dir, objects_dir,\n",
    "    binary = False)\n",
    "    create_task_behaviour(behaviour_list,colapse_behaviour,object_fixed,timeline_list,day_list)\n",
    "    navigation_list, exploration_list = create_corners_occupation(behaviour_list, corners_list, speed_list,day_list)\n",
    "    data_transformation = transform_neural_data_lda(activity_list,corners_list,parameters_time,parameters_list,parameters_list2,timeline_list,day_list)    \n",
    "    combination_corners = []\n",
    "    for i in range(len(navigation_list)):\n",
    "        combination_corners.append(navigation_list[i] + 10*exploration_list[i])\n",
    "    id_target_combination = [1,2,3,4,10,20,30,40]\n",
    "    trial_activity, trial_activity_shuffle, evnets_id, distance = compute_distance(activity_list,data_transformation,period,combination_corners,id_target_combination,N_SHUFFLINGS,data_transformation.trials,metric = metric_use)\n",
    "    output_directory = '/home/melisamc/Documentos/neural_analysis/data/mean_representational_distance/distance_matrix_lda/'\n",
    "    distance_matrix_file = output_directory + 'distance_matrix_mouse_' + f'{mouse}' +'_session_'+ f'{session_now}' +'.daily_zscored.npy'\n",
    "    np.save(distance_matrix_file,distance)\n",
    "    \n",
    "# #     ##### TRIAL TRANSFORMATIONS ####\n",
    "    activity_list_trial,timeline_list_trial,behaviour_list_trial,corners_list_trial,parameters_time_trial,parameters_list_trial,parameters_list2_trial, speed_list_trial,trial_list,tracking_list_trial = load_data_trial(mouse, session_now,decoding_v, motion_correction_v, alignment_v, equalization_v,source_extraction_v,component_evaluation_v, re_sf,file_directory, timeline_file_dir, behaviour_dir, behaviour_dir_parameters, tracking_dir, objects_dir,binary = False)\n",
    "\n",
    "    create_task_behaviour_trial(behaviour_list_trial,colapse_behaviour,object_fixed,timeline_list_trial,trial_list)    \n",
    "    navigation_list_trial, exploration_list_trial = create_corners_occupation(behaviour_list_trial, corners_list_trial, speed_list_trial,trial_list)   \n",
    "    data_transformation_trial = transform_neural_data_lda(activity_list_trial,corners_list_trial,parameters_time_trial,parameters_list_trial,parameters_list2_trial,timeline_list_trial,trial_list)\n",
    "    combination_corners_trial = corners_list_trial\n",
    "    id_target_combination = [1,2,3,4]\n",
    "    \n",
    "    trial_activity, trial_activity_shuffle, events_id, distance = compute_distance(activity_list_trial,data_transformation_trial,period,combination_corners_trial,id_target_combination,N_SHUFFLINGS,data_transformation_trial.trials,metric = metric_use,trial_flag = True)\n",
    "    output_directory = '/home/melisamc/Documentos/neural_analysis/data/mean_representational_distance/distance_matrix_lda/'\n",
    "    distance_matrix_file = output_directory + 'distance_matrix_mouse_' + f'{mouse}' +'_session_'+ f'{session_now}' +'_trial_based_zscored_1.npy'\n",
    "    np.save(distance_matrix_file,distance)\n",
    "    \n",
    "    data_transformation_trial_2 = transform_neural_data_lda(activity_list, corners_list,parameters_time,parameters_list,parameters_list2,timeline_list,day_list,trial_flag = True)\n",
    "    trial_activity, trial_activity_shuffle, events_id,distance = compute_distance(activity_list_trial,data_transformation_trial_2,period,combination_corners_trial,id_target_combination,N_SHUFFLINGS,data_transformation_trial.trials,metric = metric_use,trial_flag = True)\n",
    "    output_directory = '/home/melisamc/Documentos/neural_analysis/data/mean_representational_distance/distance_matrix_lda/'\n",
    "    distance_matrix_file = output_directory + 'distance_matrix_mouse_' + f'{mouse}' +'_session_'+ f'{session_now}' +'_trial_based_zscored_2.npy'\n",
    "    np.save(distance_matrix_file,distance)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c4b28ed-97ac-4d8b-b7e6-8806619831f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38103\n",
      "3254\n",
      "35178\n",
      "3358\n",
      "37485\n",
      "3236\n",
      "36481\n",
      "3196\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b44291b-2037-42a0-a4cf-2431f7de334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data_transformation(lda=[[], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []], trials=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_transformation_trial_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1aee1be7-f2b0-485b-b27d-5dfa039e416d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d6ec2c-9b12-4bcc-9421-28a46a6f4b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
