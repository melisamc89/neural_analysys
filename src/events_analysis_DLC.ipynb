{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of exploratory behaviour and resting periods\n",
    "\n",
    "''' Created on Wed 28 April 2021'''\n",
    "\n",
    "\n",
    "In this notebook we will analyze periods of ethogram exploration as classifyed with DLC. \n",
    "\n",
    "First we will extract the pre and post onset signal, aligned to the time when the events start. We will compute a mean population vector in the vecinity of the onset, and then analyze the full data by computing the signal correlation matrix and the noise correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import pickle\n",
    "import configuration\n",
    "import general_statistics as stats\n",
    "import figures as figs\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "from scipy import signal\n",
    "from scipy import stats as sstats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import scipy\n",
    "cmap = cm.jet\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mouse information, and preprocessin versions from analysis.\n",
    "# load data for all sessions in this mouse and compute mean activity for each neuron.\n",
    "\n",
    "mouse = 56165         ### mouse number id\n",
    "decoding_v = 1            ## decoding version, normaly equal to one\n",
    "motion_correction_v = 20  ### 100 means everything was aligned, 200 means it was also equalized, 20 is for day wise\n",
    "alignment_v = 3           ## alignment version, version 3 is for day wise\n",
    "equalization_v = 0        ## equalization version\n",
    "source_extraction_v = 1   ## source extraction version\n",
    "component_evaluation_v = 1 ## component evaluation version\n",
    "\n",
    "# here we will do analysis with no registration\n",
    "# registration_v = 2        ## registration version\n",
    "sf = 10                   ## sampling frequency of the original signal \n",
    "re_sf= 10                 ## value of resampling\n",
    "session_now = 1\n",
    "period = int(3 * sf / re_sf)\n",
    "fixed = 'None'\n",
    "\n",
    "## define task for plotting. This will cahnge for other mice!!!!\n",
    "if mouse == 56165 or mouse == 32364:\n",
    "    if mouse == 56165:\n",
    "        sessions = [1,2,4]       ## sessions for this particular mouse\n",
    "    if mouse == 32364:\n",
    "        sessions = [1,2]\n",
    "    if session_now == 1:\n",
    "        task = 'OVERLAPPING'\n",
    "        colapse_behaviour = 1\n",
    "        labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "        if mouse == 32364:\n",
    "            fixed = 'LR'\n",
    "            object_fixed = 4\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "        if mouse == 56165:\n",
    "            fixed = 'UR'\n",
    "            object_fixed = 5\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]   \n",
    "\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'STABLE'\n",
    "            colapse_behaviour = 2\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "        else:\n",
    "            task = 'RANDOM'\n",
    "            colapse_behaviour = 0\n",
    "            labels =['Unlabel','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32365:\n",
    "    sessions = [2,3] ## sessions for this particular mouse\n",
    "    if session_now == 2:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "    else:\n",
    "        if session_now == 3:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'LR'\n",
    "            object_fixed = 4\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]           \n",
    "            \n",
    "if mouse == 56166:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UR'\n",
    "            object_fixed = 5\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32366:\n",
    "    sessions = [2,3] ## sessions for this particular mouse\n",
    "    if session_now == 3:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "            \n",
    "if mouse == 32363:\n",
    "    sessions = [1,2] ## sessions for this particular mouse\n",
    "    if session_now == 1:\n",
    "        task = 'RANDOM'\n",
    "        colapse_behaviour = 0\n",
    "        labels =['Rest0','Rest1', 'Navigation', 'Obj1' , 'Obj2', 'Run1', 'Run2']\n",
    "        colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]\n",
    "    else:\n",
    "        if session_now == 2:\n",
    "            task = 'OVERLAPPING'\n",
    "            fixed = 'UL'\n",
    "            object_fixed = 6\n",
    "            colapse_behaviour = 1\n",
    "            labels =['Rest0','Rest1', 'Navigation', 'Overlap_object' , 'Moving_object','RunOO' , 'RunMO' ]\n",
    "            colornames=['k',\"r\",\"deepskyblue\",\"g\",\"blue\",\"g\",\"blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = os.environ['PROJECT_DIR'] + 'neural_analysis/data/calcium_activity_day_wise/'\n",
    "timeline_file_dir = os.environ['PROJECT_DIR'] + 'neural_analysis/data/timeline/'\n",
    "behaviour_dir = os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/ethogram/' + f'{mouse}' + '/session_' + f'{session_now}' + '/'\n",
    "objects_dir= os.environ['PROJECT_DIR'] + 'calcium_imaging_behaviour/data/object_positions/'\n",
    "figure_path = os.environ['PROJECT_DIR'] +'neural_analysis/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define all relevant files names and load them into a list\n",
    "session = session_now\n",
    "\n",
    "activity_list = []\n",
    "timeline_list = []\n",
    "behaviour_list = []\n",
    "total_time = 0\n",
    "day = 0\n",
    "for trial in [1,6,11,16]:\n",
    "    \n",
    "    beh_file_name_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_day_' + f'{day+1}' + '_likelihood_0.75_ethogram.npy'\n",
    "    ## LOAD BEHAVIOUR\n",
    "    behaviour = np.load(behaviour_dir + beh_file_name_1)\n",
    "    reshape_behaviour = np.reshape(behaviour[:int(int(behaviour.shape[0]/re_sf)*re_sf)],(int(behaviour.shape[0]/re_sf),re_sf))\n",
    "    resample_beh1 = np.reshape(scipy.stats.mode(reshape_behaviour,axis=1)[0],reshape_behaviour.shape[0])\n",
    "    \n",
    "    ## LOAD TIMELINE\n",
    "    time_file_session_1 =  'mouse_'+ f'{mouse}'+'_session_'+ f'{session}' +'_trial_'+ f'{trial}'+'_v1.3.1.0_10.pkl'\n",
    "\n",
    "    timeline_file= open(timeline_file_dir + time_file_session_1,'rb')\n",
    "    timeline_info = pickle.load(timeline_file)\n",
    "    timeline_1 = np.zeros(len(timeline_info) + 1)\n",
    "    for i in range(len(timeline_info)):\n",
    "        timeline_1[i] = timeline_info[i][1]\n",
    "    timeline_1[len(timeline_info)] = behaviour.shape[0]\n",
    "    timeline = timeline_1/re_sf\n",
    "    time_lenght = 10\n",
    "    resample_timeline = timeline_1/re_sf\n",
    "    timeline_list.append(resample_timeline)\n",
    "    \n",
    "    behaviour_list.append(resample_beh1)\n",
    "    total_time = total_time + behaviour.shape[0]\n",
    "    \n",
    "    \n",
    "    file_name_session_1 = 'mouse_' + f'{mouse}' + '_session_' + f'{session}' + '_trial_'+ f'{trial}'+'_v' + f'{decoding_v}' + '.4.' + f'{motion_correction_v}' + \\\n",
    "                          '.' + f'{alignment_v}' + '.' + f'{equalization_v}' + '.' + f'{source_extraction_v}' + '.' + \\\n",
    "                          f'{component_evaluation_v}' +  '.0.npy'\n",
    "\n",
    "    ##load activity and timeline\n",
    "    activity = np.load(file_directory + file_name_session_1)\n",
    "    neural_activity1 = activity[1:,:]\n",
    "    ## z-score neural activity\n",
    "    neural_activity = sstats.zscore(neural_activity1)\n",
    "    ##downsample neural activity\n",
    "    resample_neural_activity_mean, resample_neural_activity_std = stats.resample_matrix(neural_activity=neural_activity,\n",
    "                                                                                        re_sf=re_sf)\n",
    "    \n",
    "    activity_list.append(resample_neural_activity_mean)\n",
    "    \n",
    "    day = day + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define targets of behaviour according to protocol (random, overlapping and stable)\n",
    "\n",
    "id_target = [0,1,2,3,4,5,6] # 0: unlabeled, 1:resting, 2:Navigation, 3: Obj1, 4:Obj2, 5:Run1, 6:Run2\n",
    "\n",
    "if colapse_behaviour == 0 : # RANDOM\n",
    "    for day in range(len(behaviour_list)):\n",
    "        for trial in range(5):\n",
    "            behaviour_trial = behaviour_list[day][int(timeline_list[day][2*trial]):int(timeline_list[day][2*trial+1])]\n",
    "            objects = np.unique(behaviour_trial)\n",
    "            selected_object = np.random.randint(len(objects)-4,len(objects)-2,1)\n",
    "            index0 = np.where(behaviour_trial==objects[selected_object])[0]\n",
    "            index1 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-4], behaviour_trial!=objects[selected_object]))\n",
    "            index2 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-3], behaviour_trial!=objects[selected_object]))\n",
    "            behaviour_trial[index0] = 3\n",
    "            behaviour_trial[index1] = 4\n",
    "            behaviour_trial[index2] = 4            \n",
    "            \n",
    "            index0 = np.where(behaviour_trial==objects[selected_object]+4)[0]\n",
    "            index1 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-2], behaviour_trial!=objects[selected_object]+4))\n",
    "            index2 = np.where(np.logical_and(behaviour_trial==objects[len(objects)-1], behaviour_trial!=objects[selected_object]+4))\n",
    "            behaviour_trial[index0] = 5\n",
    "            behaviour_trial[index1] = 6\n",
    "            behaviour_trial[index2] = 6 \n",
    "            \n",
    "            behaviour_list[day][int(timeline_list[day][2*trial]):int(timeline_list[day][2*trial+1])] = behaviour_trial\n",
    "\n",
    "\n",
    "if colapse_behaviour == 1 : #OVERLAPPING\n",
    "    for day in range(len(behaviour_list)):\n",
    "        behaviour_list[day][np.where(behaviour_list[day] == object_fixed)[0]] = 100\n",
    "        behaviour_list[day][np.where(np.logical_and(behaviour_list[day]>=3, behaviour_list[day]<=6))[0]] = 4\n",
    "        behaviour_list[day][np.where(behaviour_list[day] == 100)[0]] = 3        \n",
    "        behaviour_list[day][np.where(behaviour_list[day] == object_fixed +4)[0]] = 200        \n",
    "        behaviour_list[day][np.where(np.logical_and(behaviour_list[day]>=7, behaviour_list[day]<=10))[0]] = 6\n",
    "        behaviour_list[day][np.where(behaviour_list[day] == 200)[0]] = 5        \n",
    "\n",
    "\n",
    "if colapse_behaviour == 2: #STABLE\n",
    "    for day in range(len(behaviour_list)):\n",
    "        objects = np.unique(behaviour_list[day])\n",
    "        selected_object = np.random.randint(len(objects)-4,len(objects)-2,1)\n",
    "        index0 = np.where(behaviour_list[day]==objects[selected_object])[0]\n",
    "        index1 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-4], behaviour_list[day]!=objects[selected_object]))\n",
    "        index2 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-3], behaviour_list[day]!=objects[selected_object]))\n",
    "        behaviour_list[day][index0] = 3\n",
    "        behaviour_list[day][index1] = 4\n",
    "        behaviour_list[day][index2] = 4      \n",
    "    \n",
    "        index0 = np.where(behaviour_list[day]==objects[selected_object]+4)[0]\n",
    "        index1 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-2], behaviour_list[day]!=objects[selected_object]+4))\n",
    "        index2 = np.where(np.logical_and(behaviour_list[day]==objects[len(objects)-1], behaviour_list[day]!=objects[selected_object]+4))\n",
    "        behaviour_list[day][index0] = 5\n",
    "        behaviour_list[day][index1] = 6\n",
    "        behaviour_list[day][index2] = 6  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each day creates a list that counts and saves times of different events.\n",
    "\n",
    "events_day_list = []\n",
    "events_counter_day_list = []\n",
    "events_time_starts_day = []\n",
    "for day in range(len(behaviour_list)):\n",
    "    events_list = []\n",
    "    events_counter_list = []\n",
    "    events_time_starts = []\n",
    "    start_counter = 100\n",
    "    counter = 0\n",
    "    for i in range(behaviour_list[day].shape[0]):\n",
    "        if behaviour_list[day][i] != start_counter:\n",
    "            events_list.append(start_counter)\n",
    "            events_counter_list.append(counter)\n",
    "            events_time_starts.append(i)\n",
    "            start_counter = behaviour_list[day][i]\n",
    "            counter = 1\n",
    "        else:\n",
    "            counter = counter + 1\n",
    "    events_day_list.append(events_list)\n",
    "    events_counter_day_list.append(events_counter_list)\n",
    "    events_time_starts_day.append(events_time_starts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## put all events together and take neural activity from each event\n",
    "events_activity_pre_norm= []\n",
    "for target in id_target:\n",
    "    target_activity = []\n",
    "    for day in range(len(behaviour_list)):\n",
    "        events = np.array(events_day_list[day])\n",
    "        events_counter = np.array(events_counter_day_list[day])\n",
    "        events_time = np.array(events_time_starts_day[day])\n",
    "\n",
    "        position_events = np.where(events == target)[0]\n",
    "        events_duration = events_counter[position_events]   # convert to seconds\n",
    "        time = events_time[position_events]\n",
    "        i = 0\n",
    "        for event in events_duration:\n",
    "            if event > 0:\n",
    "                local_activity = activity_list[day][:,time[i]-period:time[i]+period]\n",
    "                target_activity.append(local_activity)\n",
    "            i = i + 1\n",
    "    events_activity_pre_norm.append(target_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (195,6) (448,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-88e57dccd258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mevents_activity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mid_target\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmean_events\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevents_activity_pre_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmean_z_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_events\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print('mean z score:' + f'{mean_z_score.shape}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (195,6) (448,6) "
     ]
    }
   ],
   "source": [
    "# z-score the traces\n",
    "events_activity = []\n",
    "for target in id_target:\n",
    "    mean_events = np.mean(events_activity_pre_norm[target],axis=0,keepdims=True)\n",
    "    mean_z_score = np.mean(mean_events,axis=2)\n",
    "    #print('mean z score:' + f'{mean_z_score.shape}')\n",
    "    #print('mean_events:' + f'{mean_events.shape}')\n",
    "    std_z_score = np.std(mean_events,axis=2)\n",
    "    #print(std_z_score.shape)\n",
    "    events_target = []\n",
    "    for event in range(len(events_activity_pre_norm[target])):\n",
    "        #mean_matrix = mean_z_score*np.ones_like(events_activity_pre_norm[target][event])\n",
    "        new_activity = (events_activity_pre_norm[target][event]-mean_z_score.T)/std_z_score.T\n",
    "        #print(new_activity.shape)\n",
    "        events_target.append(new_activity)\n",
    "    events_activity.append(events_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean and z-score the traces\n",
    "mean_over_events = []\n",
    "for target in id_target:\n",
    "    mean_events = np.mean(events_activity[target],axis=0)\n",
    "    mean_over_events.append(mean_events)\n",
    "    \n",
    "    \n",
    "temporal_profile = []\n",
    "pop_vector = []\n",
    "for target in id_target:\n",
    "    temporal_profile.append(np.mean(mean_over_events[target],axis=0))\n",
    "    pop_vector.append(np.mean(mean_over_events[target],axis=1))\n",
    "    \n",
    "import matplotlib as m\n",
    "\n",
    "cdict = {\n",
    "  'red'  :  ( (0.0, 0.25, .25), (0.02, .59, .59), (1., 1., 1.)),\n",
    "  'green':  ( (0.0, 0.0, 0.0), (0.02, .45, .45), (1., .97, .97)),\n",
    "  'blue' :  ( (0.0, 1.0, 1.0), (0.02, .75, .75), (1., 0.45, 0.45))\n",
    "}\n",
    "cm = m.colors.LinearSegmentedColormap('my_colormap', cdict, 1024)\n",
    "\n",
    "\n",
    "#vmin= 0\n",
    "#vmax=4\n",
    "\n",
    "fig = plt.figure()\n",
    "gs = plt.GridSpec(8, 7)\n",
    "\n",
    "x_axes = np.array([-3,-2,-1,0,1,2,3])\n",
    "for i in range(1):\n",
    "    for j in range(8):\n",
    "        if i*2+j < 7:\n",
    "            ax = fig.add_subplot(gs[0:3, j])\n",
    "            ax.set_title(labels[i*1+j]+':'+ f'{len(events_activity[i*1+j])}' , fontsize = 15)\n",
    "            if i*2+j == 0:\n",
    "                ax.set_ylabel('Neurons', fontsize = 15)\n",
    "            ax.set_xlabel('Time [s]', fontsize = 15)\n",
    "            mesh = ax.pcolormesh(mean_over_events[i*2+j], cmap = cm)\n",
    "            #mesh.set_clim(vmin,vmax)\n",
    "            ax.set_xticks(np.arange(0,len(x_axes)))\n",
    "            ax.set_xticklabels(x_axes)\n",
    "            ax.vlines(0,0,mean_over_events[i*4+j].shape[0],colors = 'k', linestyles = 'dashed')\n",
    "\n",
    "fig.colorbar(mesh,ax=ax)\n",
    "ax = fig.add_subplot(gs[4:7, 0:2])\n",
    "for target in id_target:\n",
    "    ax.plot(x_axes[:-1],temporal_profile[target], color = colornames[target])\n",
    "ax.legend(labels, fontsize = 15)\n",
    "for target in [3,4]:\n",
    "    ax.scatter(x_axes[:-1],temporal_profile[target], color = colornames[target])\n",
    "ax.vlines(0,-0.2,0.2,colors = 'k', linestyles = 'dashed')\n",
    "ax.set_xlabel('Time [s]', fontsize = 15)\n",
    "ax.set_ylabel('Mean Activity', fontsize = 15)\n",
    "ax.set_title('Temporal Profile',fontsize = 15)\n",
    "\n",
    "ax = fig.add_subplot(gs[3:5, 2:5])\n",
    "for target in id_target:\n",
    "    ax.plot(pop_vector[target], color = colornames[target])\n",
    "ax.set_xlabel('Neurons', fontsize = 15)\n",
    "ax.set_ylabel('Mean activation', fontsize = 15)\n",
    "ax.set_title('Population vector',fontsize = 15)\n",
    "\n",
    "ax = fig.add_subplot(gs[5:8, 2:5])\n",
    "mesh = ax.pcolormesh(pop_vector, cmap = 'jet')\n",
    "#vmin= -3\n",
    "#vmax=3\n",
    "#mesh.set_clim(vmin,vmax)\n",
    "#ax.imshow(pop_vector)\n",
    "ax.set_xlabel('Neurons', fontsize = 15)\n",
    "ax.set_ylabel('Mean activation', fontsize = 15)\n",
    "ax.set_title('Population vector',fontsize = 15)\n",
    "ax.legend(labels, fontsize = 15)\n",
    "#fig.colorbar(mesh,ax=ax)\n",
    "\n",
    "\n",
    "## compute euclidean distance matrix using normalization\n",
    "euclidean_distance = np.zeros((len(pop_vector),len(pop_vector)))\n",
    "for i in range(0,len(pop_vector)):\n",
    "    for j in range(0,len(pop_vector)):\n",
    "        distance = np.linalg.norm(pop_vector[i]-pop_vector[j])\n",
    "        euclidean_distance[i,j]= distance / pop_vector[i].shape\n",
    "\n",
    "ax = fig.add_subplot(gs[3:8, 5:7])\n",
    "ax.set_title('Euclidean distance', fontsize = 15)\n",
    "x = ax.imshow(euclidean_distance, cmap = 'gray')\n",
    "#x.set_clim(0,0.01)\n",
    "    \n",
    "x_pos = np.arange(-0.5,len(labels)+0.5)\n",
    "ax.set_yticks(x_pos)\n",
    "ax.set_yticklabels(labels)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(labels)\n",
    "      \n",
    "    \n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "fig.colorbar(x, ax=ax)\n",
    "    \n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(40,25)\n",
    "fig.suptitle('Calcium activity', fontsize = 25)\n",
    "\n",
    "figure_name = figure_path +'calcium_activity_unsorted_mouse_'+f'{mouse}'+'_session_'+f'{session}'+\\\n",
    "                             '_binsize_'+f'{re_sf}'+'_period_'+ f'{period}'  +'.png'\n",
    "fig.savefig(figure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sorted by mean firing rate\n",
    "\n",
    "sorted_mean_over_events = []\n",
    "signal_corr_matrix = []\n",
    "noise_corr_matrix = []\n",
    "\n",
    "signal_corr_flatten = []\n",
    "noise_corr_flatten = []\n",
    "\n",
    "for target in id_target:\n",
    "    mean_firing_rate = np.mean(mean_over_events[target], axis = 1)\n",
    "    positions = np.flip(np.argsort(mean_firing_rate))\n",
    "    data = mean_over_events[target][positions,:]\n",
    "    non_zero_positions = np.where(np.mean(data,axis=1))\n",
    "    data_non_zero = data[non_zero_positions,:]\n",
    "    data_non_zero = data_non_zero[0,:,:]\n",
    "    sorted_mean_over_events.append(data_non_zero)\n",
    "\n",
    "    positions1 = positions[np.where(mean_firing_rate[positions])]\n",
    "    corr_matrix2 = stats.corr_matrix(neural_activity = data_non_zero)\n",
    "    signal_corr_matrix.append(corr_matrix2)\n",
    "    signal_corr_flatten.append(np.array(corr_matrix2.flatten().reshape(-1,1)))\n",
    "\n",
    "    activation = events_activity[target]\n",
    "    matrix = np.zeros((positions1.shape[0],2*period*len(activation)))\n",
    "    \n",
    "    for i in range(len(activation)):\n",
    "        matrix[:,i*2*period:(i+1)*2*period] = activation[i][positions1,:] - mean_over_events[target][positions1,:]\n",
    "    \n",
    "    corr_matrix = stats.corr_matrix(neural_activity = matrix)\n",
    "    noise_corr_matrix.append(corr_matrix)\n",
    "    noise_corr_flatten.append(np.array(corr_matrix.flatten().reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,7)\n",
    "\n",
    "for target in id_target:\n",
    "    vmin= 0\n",
    "    vmax=1\n",
    "    axes[0,target].set_title(labels[target]+ f'{len(events_activity[target])}' + 'Events' , fontsize = 15)\n",
    "    axes[0,target].set_ylabel('Neurons', fontsize = 15)\n",
    "    axes[0,target].set_xlabel('Time [s]', fontsize = 15)\n",
    "    mesh = axes[0,target].pcolormesh(sorted_mean_over_events[target], cmap = cm)\n",
    "    #mesh.set_clim(vmin,vmax)\n",
    "    axes[0,target].set_xticks(np.arange(0,len(x_axes)))\n",
    "    axes[0,target].set_xticklabels(x_axes)\n",
    "    #axes[0,target].vlines(0,0,mean_over_events[i*4+j].shape[0],colors = 'k', linestyles = 'dashed')\n",
    "    fig.colorbar(mesh,ax=axes[0,target])\n",
    "\n",
    "\n",
    "    vmin_corr = -1\n",
    "    vmax_corr = 1\n",
    "    axes[1,target].set_ylabel('Neurons', fontsize = 15)\n",
    "    axes[1,target].set_xlabel('Neurons', fontsize = 15)\n",
    "    axes[1,target].set_title('Signal Correlation matrix,', fontsize = 15)\n",
    "    mesh3 = axes[1,target].pcolormesh(signal_corr_matrix[target], cmap = 'viridis')\n",
    "    mesh3.set_clim(vmin_corr,vmax_corr)\n",
    "    #fig.colorbar(mesh3,ax=axes[1,target])\n",
    "\n",
    "    axes[2,target].set_ylabel('Neurons', fontsize = 15)\n",
    "    axes[2,target].set_xlabel('Neurons', fontsize = 15)\n",
    "    axes[2,target].set_title('Noise Correlation matrix,', fontsize = 15)\n",
    "    mesh6 = axes[2,target].pcolormesh(noise_corr_matrix[target], cmap = 'viridis')\n",
    "    mesh6.set_clim(vmin_corr,vmax_corr)\n",
    "    #fig.colorbar(mesh6,ax=axes[2,target])\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_size_inches(15,40)\n",
    "fig.suptitle('Calcium activity', fontsize = 25)\n",
    "\n",
    "figure_name = figure_path +'calcium_activity_mouse_'+f'{mouse}'+'_session_'+f'{session}'+\\\n",
    "                             '_binsize_'+f'{re_sf}'+'_period_'+ f'{period}'  +'.png'\n",
    "fig.savefig(figure_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### computing distances\n",
    "\n",
    "signal_corr_flatten = []\n",
    "noise_corr_flatten = []\n",
    "\n",
    "for target in id_target:\n",
    "    corr_matrix2 = stats.corr_matrix(neural_activity = mean_over_events[target])\n",
    "    signal_corr_flatten.append(np.array(corr_matrix2.flatten().reshape(-1,1)))\n",
    "    \n",
    "    activation = events_activity[target]\n",
    "    matrix = np.zeros((activation[0].shape[0],2*period*len(activation)))\n",
    "    for i in range(len(activation)):\n",
    "        matrix[:,i*2*period:(i+1)*2*period] = activation[i] - mean_over_events[target]\n",
    "    corr_matrix = stats.corr_matrix(neural_activity = matrix)\n",
    "    noise_corr_flatten.append(np.array(corr_matrix.flatten().reshape(-1,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute distance as cosine similarity between signal and noise corr matrix\n",
    "signal_cosine_similarity = np.zeros((len(id_target),len(id_target)))\n",
    "noise_cosine_similarity = np.zeros((len(id_target),len(id_target)))\n",
    "for target1 in id_target:\n",
    "    for target2 in id_target:\n",
    "        signal_cosine_similarity[target1,target2] = cosine_similarity(signal_corr_flatten[target1].T,signal_corr_flatten[target2].T)\n",
    "        noise_cosine_similarity[target1,target2] = cosine_similarity(noise_corr_flatten[target1].T,noise_corr_flatten[target2].T)\n",
    "        #signal_cosine_similarity[target1,target2] = np.dot(signal_corr_flatten[target1].T,signal_corr_flatten[target2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2)\n",
    "mesh0 = axes[0].pcolormesh(signal_cosine_similarity, cmap = 'gray')\n",
    "vmin= 0\n",
    "vmax=0.2\n",
    "mesh0.set_clim(vmin,vmax)\n",
    "fig.colorbar(mesh0,ax=axes[0])\n",
    "axes[0].set_title('Cosine Similarity Signal Correlation Matrix', fontsize = 15)\n",
    "\n",
    "mesh1 = axes[1].pcolormesh(noise_cosine_similarity, cmap = 'gray')\n",
    "vmin= 0\n",
    "vmax=1\n",
    "mesh1.set_clim(vmin,vmax)\n",
    "fig.colorbar(mesh1,ax=axes[1])\n",
    "axes[1].set_title('Cosine Similarity Noise Correlation Matrix', fontsize = 15)\n",
    "\n",
    "for i in [0,1]:\n",
    "    x_pos = np.arange(0,len(labels))\n",
    "    axes[i].set_yticks(x_pos)\n",
    "    axes[i].set_yticklabels(labels)\n",
    "    axes[i].set_xticks(x_pos)\n",
    "    axes[i].set_xticklabels(labels)\n",
    "    plt.setp(axes[i].get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    \n",
    "fig.set_size_inches(15,7)\n",
    "fig.suptitle('Correlation matrix similarity in different states', fontsize = 25)\n",
    "\n",
    "figure_name = figure_path +'Correlation_matrix_signal_and_noise_cosine_similarity_mouse_'+f'{mouse}'+'_session_'+f'{session}'+\\\n",
    "                             '_binsize_'+f'{re_sf}'+'_period_'+ f'{period}'  +'.png'\n",
    "fig.savefig(figure_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
